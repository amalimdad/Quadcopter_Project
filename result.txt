Episode =    1, reward =  30.000 (best reward=  30.000), step=  10 agent_position = ( -0.118, -0.015,  0.000) 
Episode =    2, reward =  30.000 (best reward=  30.000), step=  20 agent_position = ( -0.098, -0.035,  0.000) 
Episode =    3, reward =  30.000 (best reward=  30.000), step=  30 agent_position = ( -0.120, -0.012,  0.000) 
Episode =    4, reward =  30.000 (best reward=  30.000), step=  40 agent_position = ( -0.125, -0.014,  0.000) 
Episode =    5, reward =  30.000 (best reward=  30.000), step=  50 agent_position = ( -0.116, -0.032,  0.000) 
Episode =    6, reward =  30.000 (best reward=  30.000), step=  60 agent_position = ( -0.121, -0.015,  0.000) 
Episode =    7, reward =  30.000 (best reward=  30.000), step=  70 agent_position = (  0.027, -0.087,  0.000) 
Episode =    8, reward =  39.000 (best reward=  39.000), step=  83 agent_position = ( -0.605,  0.885,  0.000) 
Episode =    9, reward =  30.000 (best reward=  39.000), step=  93 agent_position = ( -0.766,  0.018,  0.000) 
Episode =   10, reward =  30.000 (best reward=  39.000), step= 103 agent_position = ( -0.264, -0.082,  0.000) 
Episode =   11, reward =  36.000 (best reward=  39.000), step= 115 agent_position = ( -0.032,  0.177,  0.000) 
Episode =   12, reward =  30.000 (best reward=  39.000), step= 125 agent_position = (  0.271,  0.196,  0.000) 
Episode =   13, reward =  27.000 (best reward=  39.000), step= 134 agent_position = (  0.015, -0.120,  0.000) 
Episode =   14, reward =  24.000 (best reward=  39.000), step= 142 agent_position = ( -0.207,  0.206,  0.000) 
Episode =   15, reward =  21.000 (best reward=  39.000), step= 149 agent_position = ( -0.131,  0.221,  0.000) 
Episode =   16, reward =  21.000 (best reward=  39.000), step= 156 agent_position = ( -0.177,  0.480,  0.000) 
Episode =   17, reward =  24.000 (best reward=  39.000), step= 164 agent_position = (  0.055,  0.156,  0.000) 
Episode =   18, reward =  24.000 (best reward=  39.000), step= 172 agent_position = ( -0.001, -0.052,  0.000) 
Episode =   19, reward =  24.000 (best reward=  39.000), step= 180 agent_position = ( -0.031, -0.001,  0.000) 
Episode =   20, reward =  24.000 (best reward=  39.000), step= 188 agent_position = ( -0.038, -0.000,  0.000) 
Episode =   21, reward =  24.000 (best reward=  39.000), step= 196 agent_position = ( -0.066,  0.001,  0.000) 
Episode =   22, reward =  24.000 (best reward=  39.000), step= 204 agent_position = ( -0.056, -0.001,  0.000) 
Episode =   23, reward =  24.000 (best reward=  39.000), step= 212 agent_position = (  0.008,  0.000,  0.000) 
Episode =   24, reward =  24.000 (best reward=  39.000), step= 220 agent_position = ( -0.040, -0.000,  0.000) 
Episode =   25, reward =  24.000 (best reward=  39.000), step= 228 agent_position = ( -0.068,  0.000,  0.000) 
Episode =   26, reward =  24.000 (best reward=  39.000), step= 236 agent_position = (  0.031,  0.000,  0.000) 
Episode =   27, reward =  24.000 (best reward=  39.000), step= 244 agent_position = ( -0.154, -0.000,  0.000) 
Episode =   28, reward =  27.000 (best reward=  39.000), step= 253 agent_position = ( -0.314,  0.000,  0.000) 
Episode =   29, reward =  30.000 (best reward=  39.000), step= 263 agent_position = ( -0.582,  0.000,  0.000) 
Episode =   30, reward =  48.000 (best reward=  48.000), step= 279 agent_position = ( -2.975,  0.003,  0.000) 
Episode =   31, reward =  63.000 (best reward=  63.000), step= 300 agent_position = ( -2.996,  0.004,  0.000) 
Episode =   32, reward =  33.000 (best reward=  63.000), step= 311 agent_position = ( -0.145,  0.000,  0.000) 
Episode =   33, reward =  30.000 (best reward=  63.000), step= 321 agent_position = ( -0.134, -0.000,  0.000) 
Episode =   34, reward =  42.000 (best reward=  63.000), step= 335 agent_position = ( -1.082,  0.000,  0.000) 
Episode =   35, reward =  30.000 (best reward=  63.000), step= 345 agent_position = ( -0.218, -0.000,  0.000) 
Episode =   36, reward =  30.000 (best reward=  63.000), step= 355 agent_position = ( -0.340,  0.000,  0.000) 
Episode =   37, reward =  33.000 (best reward=  63.000), step= 366 agent_position = ( -0.291,  0.000,  0.000) 
Episode =   38, reward =  33.000 (best reward=  63.000), step= 377 agent_position = ( -0.360,  0.000,  0.000) 
Episode =   39, reward =  36.000 (best reward=  63.000), step= 389 agent_position = ( -0.435,  0.000,  0.000) 
Episode =   40, reward =  30.000 (best reward=  63.000), step= 399 agent_position = ( -0.691,  0.000,  0.000) 
Episode =   41, reward =  27.000 (best reward=  63.000), step= 408 agent_position = ( -0.631, -0.000,  0.000) 
Episode =   42, reward =  27.000 (best reward=  63.000), step= 417 agent_position = ( -0.631, -0.000,  0.000) 
Episode =   43, reward =  30.000 (best reward=  63.000), step= 427 agent_position = ( -0.658,  0.000,  0.000) 
Episode =   44, reward =  33.000 (best reward=  63.000), step= 438 agent_position = ( -0.745,  0.000,  0.000) 
Episode =   45, reward =  27.000 (best reward=  63.000), step= 447 agent_position = (  0.172, -0.000,  0.000) 
Episode =   46, reward =  24.000 (best reward=  63.000), step= 455 agent_position = (  0.150, -0.000,  0.000) 
Episode =   47, reward =  24.000 (best reward=  63.000), step= 463 agent_position = (  0.166, -0.000,  0.000) 
Episode =   48, reward =  30.000 (best reward=  63.000), step= 473 agent_position = (  0.001, -0.000,  0.000) 
Episode =   49, reward =  30.000 (best reward=  63.000), step= 483 agent_position = ( -0.095, -0.000,  0.000) 
Episode =   50, reward =  30.000 (best reward=  63.000), step= 493 agent_position = ( -0.055,  0.000,  0.000) 
Episode =   51, reward =  30.000 (best reward=  63.000), step= 503 agent_position = ( -0.119, -0.000,  0.000) 
Episode =   52, reward =  30.000 (best reward=  63.000), step= 513 agent_position = ( -0.136, -0.000,  0.000) 
Episode =   53, reward =  30.000 (best reward=  63.000), step= 523 agent_position = ( -0.159, -0.000,  0.000) 
Episode =   54, reward =  27.000 (best reward=  63.000), step= 532 agent_position = ( -0.180, -0.000,  0.000) 
Episode =   55, reward =  27.000 (best reward=  63.000), step= 541 agent_position = ( -0.189, -0.000,  0.000) 
Episode =   56, reward =  27.000 (best reward=  63.000), step= 550 agent_position = ( -0.189, -0.000,  0.000) 
Episode =   57, reward =  27.000 (best reward=  63.000), step= 559 agent_position = ( -0.192,  0.000,  0.000) 
Episode =   58, reward =  27.000 (best reward=  63.000), step= 568 agent_position = ( -0.200,  0.000,  0.000) 
Episode =   59, reward =  27.000 (best reward=  63.000), step= 577 agent_position = ( -0.200,  0.000,  0.000) 
Episode =   60, reward =  27.000 (best reward=  63.000), step= 586 agent_position = ( -0.205,  0.000,  0.000) 
Episode =   61, reward =  27.000 (best reward=  63.000), step= 595 agent_position = ( -0.166, -0.000,  0.000) 
Episode =   62, reward =  27.000 (best reward=  63.000), step= 604 agent_position = ( -0.207,  0.000,  0.000) 
Episode =   63, reward =  27.000 (best reward=  63.000), step= 613 agent_position = ( -0.208,  0.000,  0.000) 
Episode =   64, reward =  27.000 (best reward=  63.000), step= 622 agent_position = ( -0.205,  0.000,  0.000) 
Episode =   65, reward =  27.000 (best reward=  63.000), step= 631 agent_position = ( -0.136, -0.000,  0.000) 
Episode =   66, reward =  27.000 (best reward=  63.000), step= 640 agent_position = ( -0.209, -0.000,  0.000) 
Episode =   67, reward =  27.000 (best reward=  63.000), step= 649 agent_position = ( -0.204,  0.000,  0.000) 
Episode =   68, reward =  27.000 (best reward=  63.000), step= 658 agent_position = ( -0.197, -0.000,  0.000) 
Episode =   69, reward =  27.000 (best reward=  63.000), step= 667 agent_position = ( -0.200, -0.000,  0.000) 
Episode =   70, reward =  27.000 (best reward=  63.000), step= 676 agent_position = ( -0.196, -0.000,  0.000) 
Episode =   71, reward =  27.000 (best reward=  63.000), step= 685 agent_position = ( -0.186, -0.000,  0.000) 
Episode =   72, reward =  27.000 (best reward=  63.000), step= 694 agent_position = ( -0.185, -0.000,  0.000) 
Episode =   73, reward =  27.000 (best reward=  63.000), step= 703 agent_position = ( -0.192, -0.000,  0.000) 
Episode =   74, reward =  27.000 (best reward=  63.000), step= 712 agent_position = ( -0.197, -0.000,  0.000) 
Episode =   75, reward =  27.000 (best reward=  63.000), step= 721 agent_position = ( -0.200, -0.000,  0.000) 
Episode =   76, reward =  27.000 (best reward=  63.000), step= 730 agent_position = ( -0.204, -0.000,  0.000) 
Episode =   77, reward =  27.000 (best reward=  63.000), step= 739 agent_position = ( -0.211,  0.000,  0.000) 
Episode =   78, reward =  27.000 (best reward=  63.000), step= 748 agent_position = ( -0.204,  0.000,  0.000) 
Episode =   79, reward =  27.000 (best reward=  63.000), step= 757 agent_position = ( -0.157, -0.000,  0.000) 
Episode =   80, reward =  27.000 (best reward=  63.000), step= 766 agent_position = ( -0.203,  0.000,  0.000) 
Episode =   81, reward =  27.000 (best reward=  63.000), step= 775 agent_position = ( -0.209, -0.000,  0.000) 
Episode =   82, reward =  27.000 (best reward=  63.000), step= 784 agent_position = ( -0.207, -0.000,  0.000) 
Episode =   83, reward =  27.000 (best reward=  63.000), step= 793 agent_position = ( -0.199, -0.000,  0.000) 
Episode =   84, reward =  27.000 (best reward=  63.000), step= 802 agent_position = ( -0.206,  0.000,  0.000) 
Episode =   85, reward =  27.000 (best reward=  63.000), step= 811 agent_position = ( -0.207,  0.000,  0.000) 
Episode =   86, reward =  27.000 (best reward=  63.000), step= 820 agent_position = ( -0.202, -0.000,  0.000) 
Episode =   87, reward =  27.000 (best reward=  63.000), step= 829 agent_position = ( -0.206, -0.000,  0.000) 
Episode =   88, reward =  27.000 (best reward=  63.000), step= 838 agent_position = ( -0.208,  0.000,  0.000) 
Episode =   89, reward =  27.000 (best reward=  63.000), step= 847 agent_position = ( -0.205,  0.000,  0.000) 
Episode =   90, reward =  27.000 (best reward=  63.000), step= 856 agent_position = ( -0.209,  0.000,  0.000) 
Episode =   91, reward =  27.000 (best reward=  63.000), step= 865 agent_position = ( -0.107,  0.000,  0.000) 
Episode =   92, reward =  27.000 (best reward=  63.000), step= 874 agent_position = ( -0.205,  0.000,  0.000) 
Episode =   93, reward =  27.000 (best reward=  63.000), step= 883 agent_position = ( -0.209,  0.000,  0.000) 
Episode =   94, reward =  27.000 (best reward=  63.000), step= 892 agent_position = ( -0.212, -0.000,  0.000) 
Episode =   95, reward =  27.000 (best reward=  63.000), step= 901 agent_position = ( -0.205,  0.000,  0.000) 
Episode =   96, reward =  27.000 (best reward=  63.000), step= 910 agent_position = ( -0.209,  0.000,  0.000) 
Episode =   97, reward =  27.000 (best reward=  63.000), step= 919 agent_position = ( -0.209, -0.000,  0.000) 
Episode =   98, reward =  27.000 (best reward=  63.000), step= 928 agent_position = ( -0.212, -0.000,  0.000) 
Episode =   99, reward =  27.000 (best reward=  63.000), step= 937 agent_position = ( -0.206,  0.000,  0.000) 
Episode =  100, reward =  27.000 (best reward=  63.000), step= 946 agent_position = ( -0.199,  0.000,  0.000) 
Episode =  101, reward =  27.000 (best reward=  63.000), step= 955 agent_position = ( -0.207, -0.000,  0.000) 
Episode =  102, reward =  27.000 (best reward=  63.000), step= 964 agent_position = ( -0.211,  0.000,  0.000) 
Episode =  103, reward =  27.000 (best reward=  63.000), step= 973 agent_position = ( -0.207, -0.000,  0.000) 
Episode =  104, reward =  27.000 (best reward=  63.000), step= 982 agent_position = ( -0.200, -0.000,  0.000) 
Episode =  105, reward =  27.000 (best reward=  63.000), step= 991 agent_position = ( -0.207, -0.000,  0.000) 
Episode =  106, reward =  27.000 (best reward=  63.000), step=1000 agent_position = ( -0.205, -0.000,  0.000) 
Episode =  107, reward =  27.000 (best reward=  63.000), step=1009 agent_position = ( -0.201,  0.000,  0.000) 
Episode =  108, reward =  27.000 (best reward=  63.000), step=1018 agent_position = ( -0.155, -0.000,  0.000) 
Episode =  109, reward =  27.000 (best reward=  63.000), step=1027 agent_position = ( -0.207, -0.000,  0.000) 
Episode =  110, reward =  30.000 (best reward=  63.000), step=1037 agent_position = ( -0.106, -0.000,  0.000) 
Episode =  111, reward =  27.000 (best reward=  63.000), step=1046 agent_position = ( -0.204,  0.000,  0.000) 
Episode =  112, reward =  27.000 (best reward=  63.000), step=1055 agent_position = ( -0.209, -0.000,  0.000) 
Episode =  113, reward =  27.000 (best reward=  63.000), step=1064 agent_position = ( -0.210,  0.000,  0.000) 
Episode =  114, reward =  27.000 (best reward=  63.000), step=1073 agent_position = ( -0.205,  0.000,  0.000) 
Episode =  115, reward =  27.000 (best reward=  63.000), step=1082 agent_position = ( -0.204,  0.000,  0.000) 
Episode =  116, reward =  27.000 (best reward=  63.000), step=1091 agent_position = ( -0.204, -0.000,  0.000) 
Episode =  117, reward =  27.000 (best reward=  63.000), step=1100 agent_position = ( -0.165,  0.000,  0.000) 
Episode =  118, reward =  27.000 (best reward=  63.000), step=1109 agent_position = ( -0.203,  0.000,  0.000) 
Episode =  119, reward =  27.000 (best reward=  63.000), step=1118 agent_position = ( -0.192,  0.000,  0.000) 
Episode =  120, reward =  27.000 (best reward=  63.000), step=1127 agent_position = ( -0.206,  0.000,  0.000) 
Episode =  121, reward =  27.000 (best reward=  63.000), step=1136 agent_position = ( -0.208,  0.000,  0.000) 
Episode =  122, reward =  27.000 (best reward=  63.000), step=1145 agent_position = ( -0.210, -0.000,  0.000) 
Episode =  123, reward =  27.000 (best reward=  63.000), step=1154 agent_position = ( -0.215, -0.000,  0.000) 
Episode =  124, reward =  27.000 (best reward=  63.000), step=1163 agent_position = ( -0.204,  0.000,  0.000) 
Episode =  125, reward =  27.000 (best reward=  63.000), step=1172 agent_position = ( -0.205, -0.000,  0.000) 
Episode =  126, reward =  27.000 (best reward=  63.000), step=1181 agent_position = ( -0.208, -0.000,  0.000) 
Episode =  127, reward =  27.000 (best reward=  63.000), step=1190 agent_position = ( -0.212, -0.000,  0.000) 
Episode =  128, reward =  27.000 (best reward=  63.000), step=1199 agent_position = ( -0.209, -0.000,  0.000) 
Episode =  129, reward =  27.000 (best reward=  63.000), step=1208 agent_position = ( -0.212,  0.000,  0.000) 
Episode =  130, reward =  27.000 (best reward=  63.000), step=1217 agent_position = ( -0.204, -0.000,  0.000) 
Episode =  131, reward =  33.000 (best reward=  63.000), step=1228 agent_position = ( -0.566, -0.312,  0.000) 
Episode =  132, reward =  27.000 (best reward=  63.000), step=1237 agent_position = ( -0.899,  0.142,  0.000) 
Episode =  133, reward =  36.000 (best reward=  63.000), step=1249 agent_position = ( -0.348, -0.309,  0.000) 
Episode =  134, reward =  30.000 (best reward=  63.000), step=1259 agent_position = ( -0.406, -0.793,  0.000) 
Episode =  135, reward =  54.000 (best reward=  63.000), step=1277 agent_position = ( -0.766, -2.835,  0.000) 
Episode =  136, reward =  48.000 (best reward=  63.000), step=1293 agent_position = ( -0.716, -2.375,  0.000) 
Episode =  137, reward =  51.000 (best reward=  63.000), step=1310 agent_position = ( -0.737, -2.558,  0.000) 
Episode =  138, reward =  54.000 (best reward=  63.000), step=1328 agent_position = ( -0.744, -2.968,  0.000) 
Episode =  139, reward =  51.000 (best reward=  63.000), step=1345 agent_position = ( -0.731, -2.577,  0.000) 
Episode =  140, reward =  54.000 (best reward=  63.000), step=1363 agent_position = ( -0.792, -2.828,  0.000) 
Episode =  141, reward =  63.000 (best reward=  63.000), step=1384 agent_position = ( -0.909, -3.863,  0.000) 
Episode =  142, reward =  51.000 (best reward=  63.000), step=1401 agent_position = ( -0.734, -2.591,  0.000) 
Episode =  143, reward =  51.000 (best reward=  63.000), step=1418 agent_position = ( -0.727, -2.643,  0.000) 
Episode =  144, reward =  60.000 (best reward=  63.000), step=1438 agent_position = ( -0.875, -3.591,  0.000) 
Episode =  145, reward =  60.000 (best reward=  63.000), step=1458 agent_position = ( -0.911, -3.509,  0.000) 
Episode =  146, reward =  54.000 (best reward=  63.000), step=1476 agent_position = ( -0.758, -2.920,  0.000) 
Episode =  147, reward =  54.000 (best reward=  63.000), step=1494 agent_position = ( -0.763, -2.905,  0.000) 
Episode =  148, reward =  60.000 (best reward=  63.000), step=1514 agent_position = ( -0.895, -3.485,  0.000) 
Episode =  149, reward =  39.000 (best reward=  63.000), step=1527 agent_position = ( -0.467, -1.275,  0.000) 
Episode =  150, reward =  36.000 (best reward=  63.000), step=1539 agent_position = ( -0.158, -0.718,  0.000) 
Episode =  151, reward =  27.000 (best reward=  63.000), step=1548 agent_position = ( -0.458,  0.235,  0.000) 
Episode =  152, reward =  24.000 (best reward=  63.000), step=1556 agent_position = (  0.756, -0.054,  0.000) 
Episode =  153, reward =  30.000 (best reward=  63.000), step=1566 agent_position = ( -1.429,  0.492,  0.000) 
Episode =  154, reward =  30.000 (best reward=  63.000), step=1576 agent_position = ( -0.279,  0.646,  0.000) 
Episode =  155, reward =  27.000 (best reward=  63.000), step=1585 agent_position = ( -0.076,  0.541,  0.000) 
Episode =  156, reward =  30.000 (best reward=  63.000), step=1595 agent_position = ( -0.096,  0.634,  0.000) 
Episode =  157, reward =  42.000 (best reward=  63.000), step=1609 agent_position = (  0.090,  2.194,  0.000) 
Episode =  158, reward =  27.000 (best reward=  63.000), step=1618 agent_position = ( -0.065, -0.535,  0.000) 
Episode =  159, reward =  30.000 (best reward=  63.000), step=1628 agent_position = ( -0.051,  0.648,  0.000) 
Episode =  160, reward =  27.000 (best reward=  63.000), step=1637 agent_position = ( -0.016,  0.537,  0.000) 
Episode =  161, reward =  27.000 (best reward=  63.000), step=1646 agent_position = ( -0.006,  0.538,  0.000) 
Episode =  162, reward =  30.000 (best reward=  63.000), step=1656 agent_position = ( -0.009,  0.634,  0.000) 
Episode =  163, reward =  27.000 (best reward=  63.000), step=1665 agent_position = ( -0.002,  0.533,  0.000) 
Episode =  164, reward =  30.000 (best reward=  63.000), step=1675 agent_position = ( -0.002,  0.637,  0.000) 
Episode =  165, reward =  27.000 (best reward=  63.000), step=1684 agent_position = ( -0.001,  0.535,  0.000) 
Episode =  166, reward =  27.000 (best reward=  63.000), step=1693 agent_position = ( -0.001,  0.534,  0.000) 
Episode =  167, reward =  30.000 (best reward=  63.000), step=1703 agent_position = ( -0.008,  0.628,  0.000) 
Episode =  168, reward =  27.000 (best reward=  63.000), step=1712 agent_position = ( -0.001,  0.535,  0.000) 
Episode =  169, reward =  30.000 (best reward=  63.000), step=1722 agent_position = ( -0.004,  0.620,  0.000) 
Episode =  170, reward =  30.000 (best reward=  63.000), step=1732 agent_position = ( -0.005,  0.623,  0.000) 
Episode =  171, reward =  27.000 (best reward=  63.000), step=1741 agent_position = ( -0.000,  0.533,  0.000) 
Episode =  172, reward =  30.000 (best reward=  63.000), step=1751 agent_position = ( -0.002,  0.623,  0.000) 
Episode =  173, reward =  30.000 (best reward=  63.000), step=1761 agent_position = ( -0.001,  0.599,  0.000) 
Episode =  174, reward =  33.000 (best reward=  63.000), step=1772 agent_position = ( -0.001, -0.894,  0.000) 
Episode =  175, reward =  27.000 (best reward=  63.000), step=1781 agent_position = ( -0.000, -0.827,  0.000) 
Episode =  176, reward =  39.000 (best reward=  63.000), step=1794 agent_position = ( -0.001,  0.703,  0.000) 
Episode =  177, reward =  24.000 (best reward=  63.000), step=1802 agent_position = ( -0.000,  0.151,  0.000) 
Episode =  178, reward =  69.000 (best reward=  69.000), step=1825 agent_position = ( -0.330,  1.335,  0.000) 
Episode =  179, reward =  39.000 (best reward=  69.000), step=1838 agent_position = ( -0.803,  0.667,  0.000) 
Episode =  180, reward =  33.000 (best reward=  69.000), step=1849 agent_position = ( -0.886,  0.209,  0.000) 
Episode =  181, reward =  48.000 (best reward=  69.000), step=1865 agent_position = ( -0.805,  0.589,  0.000) 
Episode =  182, reward =  45.000 (best reward=  69.000), step=1880 agent_position = ( -0.001, -3.570,  0.000) 
Episode =  183, reward =  63.000 (best reward=  69.000), step=1901 agent_position = ( -0.020,  5.746,  0.000) 
Episode =  184, reward =  69.000 (best reward=  69.000), step=1924 agent_position = ( -0.864,  0.017,  0.000) 
Episode =  185, reward =  39.000 (best reward=  69.000), step=1937 agent_position = ( -0.017, -0.234,  0.000) 
Episode =  186, reward =  63.000 (best reward=  69.000), step=1958 agent_position = ( -3.684,  4.659,  0.000) 
Episode =  187, reward =  27.000 (best reward=  69.000), step=1967 agent_position = (  0.898, -0.416,  0.000) 
Episode =  188, reward =  39.000 (best reward=  69.000), step=1980 agent_position = ( -0.478,  0.283,  0.000) 
Episode =  189, reward =  48.000 (best reward=  69.000), step=1996 agent_position = (  0.297,  0.515,  0.000) 
Episode =  190, reward =  33.000 (best reward=  69.000), step=2007 agent_position = (  1.485,  0.959,  0.000) 
Episode =  191, reward =  45.000 (best reward=  69.000), step=2022 agent_position = ( -1.328,  0.869,  0.000) 
Episode =  192, reward =  42.000 (best reward=  69.000), step=2036 agent_position = ( -1.831,  1.517,  0.000) 
Episode =  193, reward =  36.000 (best reward=  69.000), step=2048 agent_position = ( -1.970,  0.496,  0.000) 
Episode =  194, reward =  36.000 (best reward=  69.000), step=2060 agent_position = ( -1.754,  0.440,  0.000) 
Episode =  195, reward =  39.000 (best reward=  69.000), step=2073 agent_position = ( -0.366,  0.755,  0.000) 
Episode =  196, reward =  45.000 (best reward=  69.000), step=2088 agent_position = ( -1.730, -0.202,  0.000) 
Episode =  197, reward =  36.000 (best reward=  69.000), step=2100 agent_position = ( -0.121,  0.279,  0.000) 
Episode =  198, reward =  30.000 (best reward=  69.000), step=2110 agent_position = ( -0.180,  0.609,  0.000) 
Episode =  199, reward =  42.000 (best reward=  69.000), step=2124 agent_position = ( -0.429,  0.075,  0.000) 
Episode =  200, reward =  39.000 (best reward=  69.000), step=2137 agent_position = ( -2.068,  0.511,  0.000) 
Episode =  201, reward =  27.000 (best reward=  69.000), step=2146 agent_position = (  1.312,  0.437,  0.000) 
Episode =  202, reward =  33.000 (best reward=  69.000), step=2157 agent_position = (  0.962,  0.341,  0.000) 
Episode =  203, reward =  36.000 (best reward=  69.000), step=2169 agent_position = (  0.896,  0.765,  0.000) 
Episode =  204, reward =  33.000 (best reward=  69.000), step=2180 agent_position = (  0.558,  0.480,  0.000) 
Episode =  205, reward =  33.000 (best reward=  69.000), step=2191 agent_position = ( -0.624,  0.723,  0.000) 
Episode =  206, reward =  30.000 (best reward=  69.000), step=2201 agent_position = ( -0.150, -0.144,  0.000) 
Episode =  207, reward =  30.000 (best reward=  69.000), step=2211 agent_position = ( -0.173, -0.130,  0.000) 
Episode =  208, reward =  33.000 (best reward=  69.000), step=2222 agent_position = (  0.284,  0.103,  0.000) 
Episode =  209, reward =  42.000 (best reward=  69.000), step=2236 agent_position = ( -0.276,  0.513,  0.000) 
Episode =  210, reward =  42.000 (best reward=  69.000), step=2250 agent_position = ( -0.108,  0.195,  0.000) 
Episode =  211, reward =  42.000 (best reward=  69.000), step=2264 agent_position = ( -0.455,  0.357,  0.000) 
Episode =  212, reward =  42.000 (best reward=  69.000), step=2278 agent_position = ( -0.999,  0.761,  0.000) 
Episode =  213, reward =  42.000 (best reward=  69.000), step=2292 agent_position = (  0.180,  1.461,  0.000) 
Episode =  214, reward =  45.000 (best reward=  69.000), step=2307 agent_position = ( -0.067, -0.292,  0.000) 
Episode =  215, reward =  48.000 (best reward=  69.000), step=2323 agent_position = ( -0.665,  0.263,  0.000) 
Episode =  216, reward =  45.000 (best reward=  69.000), step=2338 agent_position = (  0.255,  1.495,  0.000) 
Episode =  217, reward =  42.000 (best reward=  69.000), step=2352 agent_position = ( -0.255,  0.480,  0.000) 
Episode =  218, reward =  39.000 (best reward=  69.000), step=2365 agent_position = (  0.840,  0.089,  0.000) 
Episode =  219, reward =  27.000 (best reward=  69.000), step=2374 agent_position = (  0.196, -0.127,  0.000) 
Episode =  220, reward =  27.000 (best reward=  69.000), step=2383 agent_position = (  0.000,  0.534,  0.000) 
Episode =  221, reward =  30.000 (best reward=  69.000), step=2393 agent_position = ( -0.507, -0.557,  0.000) 
Episode =  222, reward =  27.000 (best reward=  69.000), step=2402 agent_position = (  0.000,  0.535,  0.000) 
Episode =  223, reward =  27.000 (best reward=  69.000), step=2411 agent_position = ( -0.001,  0.381,  0.000) 
Episode =  224, reward =  27.000 (best reward=  69.000), step=2420 agent_position = (  0.000,  0.535,  0.000) 
Episode =  225, reward =  33.000 (best reward=  69.000), step=2431 agent_position = ( -0.000, -0.481,  0.000) 
Episode =  226, reward =  27.000 (best reward=  69.000), step=2440 agent_position = (  0.000,  0.535,  0.000) 
Episode =  227, reward =  42.000 (best reward=  69.000), step=2454 agent_position = ( -0.000, -0.579,  0.000) 
Episode =  228, reward =  24.000 (best reward=  69.000), step=2462 agent_position = ( -0.000,  0.284,  0.000) 
Episode =  229, reward =  27.000 (best reward=  69.000), step=2471 agent_position = (  0.000,  0.536,  0.000) 
Episode =  230, reward =  27.000 (best reward=  69.000), step=2480 agent_position = (  0.000,  0.533,  0.000) 
Episode =  231, reward =  27.000 (best reward=  69.000), step=2489 agent_position = (  0.000,  0.533,  0.000) 
Episode =  232, reward =  27.000 (best reward=  69.000), step=2498 agent_position = (  0.000,  0.534,  0.000) 
Episode =  233, reward =  27.000 (best reward=  69.000), step=2507 agent_position = (  0.000,  0.540,  0.000) 
Episode =  234, reward =  33.000 (best reward=  69.000), step=2518 agent_position = (  0.000,  0.069,  0.000) 
Episode =  235, reward =  27.000 (best reward=  69.000), step=2527 agent_position = (  0.000,  0.539,  0.000) 
Episode =  236, reward =  21.000 (best reward=  69.000), step=2534 agent_position = ( -0.001,  1.051,  0.000) 
Episode =  237, reward =  27.000 (best reward=  69.000), step=2543 agent_position = ( -0.017,  1.312,  0.000) 
Episode =  238, reward =  30.000 (best reward=  69.000), step=2553 agent_position = (  0.000,  0.215,  0.000) 
Episode =  239, reward =  57.000 (best reward=  69.000), step=2572 agent_position = ( -0.000, -4.197,  0.000) 
Episode =  240, reward =  27.000 (best reward=  69.000), step=2581 agent_position = (  0.000,  0.379,  0.000) 
Episode =  241, reward =  45.000 (best reward=  69.000), step=2596 agent_position = ( -1.300,  5.008,  0.000) 
Episode =  242, reward =  33.000 (best reward=  69.000), step=2607 agent_position = (  0.000,  0.690,  0.000) 
Episode =  243, reward =  30.000 (best reward=  69.000), step=2617 agent_position = (  0.000,  0.637,  0.000) 
Episode =  244, reward =  51.000 (best reward=  69.000), step=2634 agent_position = ( -1.865,  6.103,  0.000) 
Episode =  245, reward =  78.000 (best reward=  78.000), step=2660 agent_position = ( -0.037, -2.515,  0.000) 
Episode =  246, reward =  36.000 (best reward=  78.000), step=2672 agent_position = (  0.000,  0.830,  0.000) 
Episode =  247, reward =  27.000 (best reward=  78.000), step=2681 agent_position = (  0.000,  0.534,  0.000) 
Episode =  248, reward =  30.000 (best reward=  78.000), step=2691 agent_position = (  0.000,  0.636,  0.000) 
Episode =  249, reward =  42.000 (best reward=  78.000), step=2705 agent_position = ( -0.000,  3.064,  0.000) 
Episode =  250, reward =  27.000 (best reward=  78.000), step=2714 agent_position = (  0.000,  0.509,  0.000) 
Episode =  251, reward =  27.000 (best reward=  78.000), step=2723 agent_position = (  0.000,  0.537,  0.000) 
Episode =  252, reward =  33.000 (best reward=  78.000), step=2734 agent_position = (  0.000,  0.267,  0.000) 
Episode =  253, reward =  30.000 (best reward=  78.000), step=2744 agent_position = (  0.000,  0.635,  0.000) 
Episode =  254, reward =  27.000 (best reward=  78.000), step=2753 agent_position = (  0.000,  0.532,  0.000) 
Episode =  255, reward =  33.000 (best reward=  78.000), step=2764 agent_position = (  0.000,  0.273,  0.000) 
Episode =  256, reward =  24.000 (best reward=  78.000), step=2772 agent_position = ( -0.000,  0.488,  0.000) 
Episode =  257, reward =  27.000 (best reward=  78.000), step=2781 agent_position = (  0.000,  0.537,  0.000) 
Episode =  258, reward =  24.000 (best reward=  78.000), step=2789 agent_position = ( -0.000,  0.459,  0.000) 
Episode =  259, reward =  30.000 (best reward=  78.000), step=2799 agent_position = (  0.000,  0.361,  0.000) 
Episode =  260, reward =  33.000 (best reward=  78.000), step=2810 agent_position = (  0.000,  0.252,  0.000) 
Episode =  261, reward =  33.000 (best reward=  78.000), step=2821 agent_position = (  0.000,  0.283,  0.000) 
Episode =  262, reward =  36.000 (best reward=  78.000), step=2833 agent_position = (  0.000,  0.793,  0.000) 
Episode =  263, reward =  36.000 (best reward=  78.000), step=2845 agent_position = (  0.000,  0.976,  0.000) 
Episode =  264, reward =  27.000 (best reward=  78.000), step=2854 agent_position = (  0.000,  0.537,  0.000) 
Episode =  265, reward =  51.000 (best reward=  78.000), step=2871 agent_position = ( -0.000, -1.722,  0.000) 
Episode =  266, reward =  24.000 (best reward=  78.000), step=2879 agent_position = ( -0.000,  0.883,  0.000) 
Episode =  267, reward =  30.000 (best reward=  78.000), step=2889 agent_position = (  0.000, -0.131,  0.000) 
Episode =  268, reward =  48.000 (best reward=  78.000), step=2905 agent_position = ( -0.000, -3.987,  0.000) 
Episode =  269, reward =  66.000 (best reward=  78.000), step=2927 agent_position = ( -0.000, -3.037,  0.000) 
Episode =  270, reward =  81.000 (best reward=  81.000), step=2954 agent_position = ( -0.000,  7.564,  0.000) 
Episode =  271, reward =  69.000 (best reward=  81.000), step=2977 agent_position = ( -0.000, -6.608,  0.000) 
Episode =  272, reward =  21.000 (best reward=  81.000), step=2984 agent_position = (  0.000, -0.289,  0.000) 
Episode =  273, reward =  60.000 (best reward=  81.000), step=3004 agent_position = ( -0.000, -3.653,  0.000) 
Episode =  274, reward =  75.000 (best reward=  81.000), step=3029 agent_position = (  0.000, -0.234,  0.000) 
Episode =  275, reward =  54.000 (best reward=  81.000), step=3047 agent_position = ( -0.000, -4.045,  0.000) 
Episode =  276, reward = 135.000 (best reward= 135.000), step=3092 agent_position = ( -0.000, -6.408,  0.000) 
Episode =  277, reward =  39.000 (best reward= 135.000), step=3105 agent_position = (  0.000,  0.739,  0.000) 
Episode =  278, reward =  51.000 (best reward= 135.000), step=3122 agent_position = ( -0.000, -2.886,  0.000) 
Episode =  279, reward =  57.000 (best reward= 135.000), step=3141 agent_position = ( -0.000, -4.677,  0.000) 
Episode =  280, reward = 140.180 (best reward= 140.180), step=3210 agent_position = ( -0.000,-40.978,  0.000) 
Episode =  281, reward = 120.000 (best reward= 140.180), step=3250 agent_position = (  0.000, 14.442,  0.000) 
Episode =  282, reward =  36.000 (best reward= 140.180), step=3262 agent_position = ( -0.000,  1.244,  0.000) 
Episode =  283, reward = 172.216 (best reward= 172.216), step=3326 agent_position = (  0.000,-27.170,  0.000) 
Episode =  284, reward =  63.000 (best reward= 172.216), step=3347 agent_position = ( -0.000, -5.538,  0.000) 
Episode =  285, reward =  81.000 (best reward= 172.216), step=3374 agent_position = (  0.000, -6.092,  0.000) 
Episode =  286, reward =  78.000 (best reward= 172.216), step=3400 agent_position = (  0.000, -2.073,  0.000) 
Episode =  287, reward =  90.000 (best reward= 172.216), step=3430 agent_position = ( -0.000, -6.999,  0.000) 
Episode =  288, reward =  36.000 (best reward= 172.216), step=3442 agent_position = ( -0.000, -0.289,  0.000) 
Episode =  289, reward =  90.000 (best reward= 172.216), step=3472 agent_position = ( -0.000, -6.913,  0.000) 
Episode =  290, reward =  87.000 (best reward= 172.216), step=3501 agent_position = (  0.000, -7.730,  0.000) 
Episode =  291, reward = 147.000 (best reward= 172.216), step=3550 agent_position = ( -2.281, 17.147,  0.000) 
Episode =  292, reward =  39.000 (best reward= 172.216), step=3563 agent_position = ( -1.186, -0.003,  0.000) 
Episode =  293, reward =  39.000 (best reward= 172.216), step=3576 agent_position = ( -1.268,  0.066,  0.000) 
Episode =  294, reward =  30.000 (best reward= 172.216), step=3586 agent_position = ( -0.735,  0.526,  0.000) 
Episode =  295, reward =  21.000 (best reward= 172.216), step=3593 agent_position = ( -0.282,  0.182,  0.000) 
Episode =  296, reward =  24.000 (best reward= 172.216), step=3601 agent_position = ( -0.440,  0.088,  0.000) 
Episode =  297, reward =  30.000 (best reward= 172.216), step=3611 agent_position = ( -0.451,  0.846,  0.000) 
Episode =  298, reward =  36.000 (best reward= 172.216), step=3623 agent_position = ( -0.451,  0.174,  0.000) 
Episode =  299, reward =  39.000 (best reward= 172.216), step=3636 agent_position = ( -0.492,  0.446,  0.000) 
Episode =  300, reward =  33.000 (best reward= 172.216), step=3647 agent_position = ( -0.766,  0.114,  0.000) 
Episode =  301, reward =  36.000 (best reward= 172.216), step=3659 agent_position = ( -0.557,  0.448,  0.000) 
Episode =  302, reward =  39.000 (best reward= 172.216), step=3672 agent_position = ( -0.786,  0.650,  0.000) 
Episode =  303, reward =  51.000 (best reward= 172.216), step=3689 agent_position = ( -0.853,  0.033,  0.000) 
Episode =  304, reward =  36.000 (best reward= 172.216), step=3701 agent_position = ( -0.560,  0.453,  0.000) 
Episode =  305, reward =  48.000 (best reward= 172.216), step=3717 agent_position = ( -1.016,  1.073,  0.000) 
Episode =  306, reward =  45.000 (best reward= 172.216), step=3732 agent_position = ( -0.811,  0.127,  0.000) 
Episode =  307, reward =  51.000 (best reward= 172.216), step=3749 agent_position = ( -0.468,  0.284,  0.000) 
Episode =  308, reward =  39.000 (best reward= 172.216), step=3762 agent_position = ( -0.462,  1.118,  0.000) 
Episode =  309, reward =  39.000 (best reward= 172.216), step=3775 agent_position = ( -0.649, -0.059,  0.000) 
Episode =  310, reward =  36.000 (best reward= 172.216), step=3787 agent_position = ( -0.519,  0.443,  0.000) 
Episode =  311, reward =  36.000 (best reward= 172.216), step=3799 agent_position = ( -0.596,  0.383,  0.000) 
Episode =  312, reward =  42.000 (best reward= 172.216), step=3813 agent_position = ( -0.484, -0.212,  0.000) 
Episode =  313, reward =  42.000 (best reward= 172.216), step=3827 agent_position = ( -0.767,  0.747,  0.000) 
Episode =  314, reward =  51.000 (best reward= 172.216), step=3844 agent_position = ( -0.498,  0.124,  0.000) 
Episode =  315, reward =  36.000 (best reward= 172.216), step=3856 agent_position = ( -0.614,  0.426,  0.000) 
Episode =  316, reward =  36.000 (best reward= 172.216), step=3868 agent_position = ( -0.598,  0.387,  0.000) 
Episode =  317, reward =  36.000 (best reward= 172.216), step=3880 agent_position = ( -0.612,  0.439,  0.000) 
Episode =  318, reward =  36.000 (best reward= 172.216), step=3892 agent_position = ( -0.595,  0.389,  0.000) 
Episode =  319, reward =  36.000 (best reward= 172.216), step=3904 agent_position = ( -0.578,  0.379,  0.000) 
Episode =  320, reward =  36.000 (best reward= 172.216), step=3916 agent_position = ( -0.583,  0.377,  0.000) 
Episode =  321, reward =  36.000 (best reward= 172.216), step=3928 agent_position = ( -0.575,  0.351,  0.000) 
Episode =  322, reward =  36.000 (best reward= 172.216), step=3940 agent_position = ( -0.584,  0.367,  0.000) 
Episode =  323, reward =  39.000 (best reward= 172.216), step=3953 agent_position = ( -0.434,  1.178,  0.000) 
Episode =  324, reward =  39.000 (best reward= 172.216), step=3966 agent_position = ( -0.475,  0.412,  0.000) 
Episode =  325, reward =  36.000 (best reward= 172.216), step=3978 agent_position = ( -0.591,  0.403,  0.000) 
Episode =  326, reward =  36.000 (best reward= 172.216), step=3990 agent_position = ( -0.591,  0.382,  0.000) 
Episode =  327, reward =  36.000 (best reward= 172.216), step=4002 agent_position = ( -0.598,  0.414,  0.000) 
Episode =  328, reward =  36.000 (best reward= 172.216), step=4014 agent_position = ( -0.592,  0.350,  0.000) 
Episode =  329, reward =  36.000 (best reward= 172.216), step=4026 agent_position = ( -0.592,  0.392,  0.000) 
Episode =  330, reward =  36.000 (best reward= 172.216), step=4038 agent_position = ( -0.586,  0.355,  0.000) 
Episode =  331, reward =  36.000 (best reward= 172.216), step=4050 agent_position = ( -0.588,  0.359,  0.000) 
Episode =  332, reward =  39.000 (best reward= 172.216), step=4063 agent_position = ( -0.484,  0.370,  0.000) 
Episode =  333, reward =  36.000 (best reward= 172.216), step=4075 agent_position = ( -0.574,  0.349,  0.000) 
Episode =  334, reward =  36.000 (best reward= 172.216), step=4087 agent_position = ( -0.583,  0.373,  0.000) 
Episode =  335, reward =  36.000 (best reward= 172.216), step=4099 agent_position = ( -0.587,  0.426,  0.000) 
Episode =  336, reward =  36.000 (best reward= 172.216), step=4111 agent_position = ( -0.586,  0.401,  0.000) 
Episode =  337, reward =  36.000 (best reward= 172.216), step=4123 agent_position = ( -0.587,  0.392,  0.000) 
Episode =  338, reward =  39.000 (best reward= 172.216), step=4136 agent_position = ( -0.490,  0.443,  0.000) 
Episode =  339, reward =  36.000 (best reward= 172.216), step=4148 agent_position = ( -0.570,  0.368,  0.000) 
Episode =  340, reward =  36.000 (best reward= 172.216), step=4160 agent_position = ( -0.583,  0.394,  0.000) 
Episode =  341, reward =  36.000 (best reward= 172.216), step=4172 agent_position = ( -0.523,  0.310,  0.000) 
Episode =  342, reward =  36.000 (best reward= 172.216), step=4184 agent_position = ( -0.599,  0.385,  0.000) 
Episode =  343, reward =  36.000 (best reward= 172.216), step=4196 agent_position = ( -0.590,  0.398,  0.000) 
Episode =  344, reward =  36.000 (best reward= 172.216), step=4208 agent_position = ( -0.599,  0.388,  0.000) 
Episode =  345, reward =  36.000 (best reward= 172.216), step=4220 agent_position = ( -0.587,  0.371,  0.000) 
Episode =  346, reward =  42.000 (best reward= 172.216), step=4234 agent_position = ( -0.793,  0.918,  0.000) 
Episode =  347, reward =  36.000 (best reward= 172.216), step=4246 agent_position = ( -0.582,  0.382,  0.000) 
Episode =  348, reward =  36.000 (best reward= 172.216), step=4258 agent_position = ( -0.593,  0.368,  0.000) 
Episode =  349, reward =  36.000 (best reward= 172.216), step=4270 agent_position = ( -0.595,  0.390,  0.000) 
Episode =  350, reward =  36.000 (best reward= 172.216), step=4282 agent_position = ( -0.601,  0.398,  0.000) 
Episode =  351, reward =  36.000 (best reward= 172.216), step=4294 agent_position = ( -0.568,  0.348,  0.000) 
Episode =  352, reward =  36.000 (best reward= 172.216), step=4306 agent_position = ( -0.579,  0.384,  0.000) 
Episode =  353, reward =  39.000 (best reward= 172.216), step=4319 agent_position = ( -0.491,  0.499,  0.000) 
Episode =  354, reward =  36.000 (best reward= 172.216), step=4331 agent_position = ( -0.600,  0.370,  0.000) 
Episode =  355, reward =  36.000 (best reward= 172.216), step=4343 agent_position = ( -0.608,  0.387,  0.000) 
Episode =  356, reward =  36.000 (best reward= 172.216), step=4355 agent_position = ( -0.593,  0.375,  0.000) 
Episode =  357, reward =  36.000 (best reward= 172.216), step=4367 agent_position = ( -0.578,  0.346,  0.000) 
Episode =  358, reward =  36.000 (best reward= 172.216), step=4379 agent_position = ( -0.579,  0.354,  0.000) 
Episode =  359, reward =  36.000 (best reward= 172.216), step=4391 agent_position = ( -0.535,  0.358,  0.000) 
Episode =  360, reward =  36.000 (best reward= 172.216), step=4403 agent_position = ( -0.596,  0.356,  0.000) 
Episode =  361, reward =  36.000 (best reward= 172.216), step=4415 agent_position = ( -0.586,  0.364,  0.000) 
Episode =  362, reward =  36.000 (best reward= 172.216), step=4427 agent_position = ( -0.590,  0.376,  0.000) 
Episode =  363, reward =  36.000 (best reward= 172.216), step=4439 agent_position = ( -0.588,  0.398,  0.000) 
Episode =  364, reward =  36.000 (best reward= 172.216), step=4451 agent_position = ( -0.606,  0.425,  0.000) 
Episode =  365, reward =  36.000 (best reward= 172.216), step=4463 agent_position = ( -0.598,  0.442,  0.000) 
Episode =  366, reward =  36.000 (best reward= 172.216), step=4475 agent_position = ( -0.590,  0.377,  0.000) 
Episode =  367, reward =  36.000 (best reward= 172.216), step=4487 agent_position = ( -0.576,  0.347,  0.000) 
Episode =  368, reward =  36.000 (best reward= 172.216), step=4499 agent_position = ( -0.530,  0.443,  0.000) 
Episode =  369, reward =  36.000 (best reward= 172.216), step=4511 agent_position = ( -0.595,  0.397,  0.000) 
Episode =  370, reward =  36.000 (best reward= 172.216), step=4523 agent_position = ( -0.595,  0.355,  0.000) 
Episode =  371, reward =  36.000 (best reward= 172.216), step=4535 agent_position = ( -0.606,  0.365,  0.000) 
Episode =  372, reward =  36.000 (best reward= 172.216), step=4547 agent_position = ( -0.587,  0.395,  0.000) 
Episode =  373, reward =  36.000 (best reward= 172.216), step=4559 agent_position = ( -0.605,  0.365,  0.000) 
Episode =  374, reward =  36.000 (best reward= 172.216), step=4571 agent_position = ( -0.587,  0.380,  0.000) 
Episode =  375, reward =  36.000 (best reward= 172.216), step=4583 agent_position = ( -0.597,  0.408,  0.000) 
Episode =  376, reward =  36.000 (best reward= 172.216), step=4595 agent_position = ( -0.597,  0.394,  0.000) 
Episode =  377, reward =  36.000 (best reward= 172.216), step=4607 agent_position = ( -0.604,  0.381,  0.000) 
Episode =  378, reward =  36.000 (best reward= 172.216), step=4619 agent_position = ( -0.591,  0.387,  0.000) 
Episode =  379, reward =  36.000 (best reward= 172.216), step=4631 agent_position = ( -0.585,  0.370,  0.000) 
Episode =  380, reward =  36.000 (best reward= 172.216), step=4643 agent_position = ( -0.600,  0.416,  0.000) 
Episode =  381, reward =  36.000 (best reward= 172.216), step=4655 agent_position = ( -0.519,  0.392,  0.000) 
Episode =  382, reward =  36.000 (best reward= 172.216), step=4667 agent_position = ( -0.579,  0.409,  0.000) 
Episode =  383, reward =  36.000 (best reward= 172.216), step=4679 agent_position = ( -0.591,  0.379,  0.000) 
Episode =  384, reward =  36.000 (best reward= 172.216), step=4691 agent_position = ( -0.572,  0.343,  0.000) 
Episode =  385, reward =  36.000 (best reward= 172.216), step=4703 agent_position = ( -0.606,  0.404,  0.000) 
Episode =  386, reward =  36.000 (best reward= 172.216), step=4715 agent_position = ( -0.606,  0.417,  0.000) 
Episode =  387, reward =  36.000 (best reward= 172.216), step=4727 agent_position = ( -0.600,  0.381,  0.000) 
Episode =  388, reward =  36.000 (best reward= 172.216), step=4739 agent_position = ( -0.530,  0.346,  0.000) 
Episode =  389, reward =  36.000 (best reward= 172.216), step=4751 agent_position = ( -0.576,  0.369,  0.000) 
Episode =  390, reward =  36.000 (best reward= 172.216), step=4763 agent_position = ( -0.583,  0.341,  0.000) 
Episode =  391, reward =  36.000 (best reward= 172.216), step=4775 agent_position = ( -0.576,  0.368,  0.000) 
Episode =  392, reward =  36.000 (best reward= 172.216), step=4787 agent_position = ( -0.594,  0.353,  0.000) 
Episode =  393, reward =  36.000 (best reward= 172.216), step=4799 agent_position = ( -0.597,  0.383,  0.000) 
Episode =  394, reward =  36.000 (best reward= 172.216), step=4811 agent_position = ( -0.579,  0.365,  0.000) 
Episode =  395, reward =  36.000 (best reward= 172.216), step=4823 agent_position = ( -0.584,  0.355,  0.000) 
Episode =  396, reward =  36.000 (best reward= 172.216), step=4835 agent_position = ( -0.597,  0.396,  0.000) 
Episode =  397, reward =  36.000 (best reward= 172.216), step=4847 agent_position = ( -0.582,  0.400,  0.000) 
Episode =  398, reward =  36.000 (best reward= 172.216), step=4859 agent_position = ( -0.589,  0.388,  0.000) 
Episode =  399, reward =  36.000 (best reward= 172.216), step=4871 agent_position = ( -0.581,  0.331,  0.000) 
Episode =  400, reward =  36.000 (best reward= 172.216), step=4883 agent_position = ( -0.597,  0.394,  0.000) 
Episode =  401, reward =  36.000 (best reward= 172.216), step=4895 agent_position = ( -0.587,  0.380,  0.000) 
Episode =  402, reward =  36.000 (best reward= 172.216), step=4907 agent_position = ( -0.605,  0.417,  0.000) 
Episode =  403, reward =  36.000 (best reward= 172.216), step=4919 agent_position = ( -0.617,  0.443,  0.000) 
Episode =  404, reward =  36.000 (best reward= 172.216), step=4931 agent_position = ( -0.582,  0.351,  0.000) 
Episode =  405, reward =  36.000 (best reward= 172.216), step=4943 agent_position = ( -0.608,  0.413,  0.000) 
Episode =  406, reward =  36.000 (best reward= 172.216), step=4955 agent_position = ( -0.602,  0.351,  0.000) 
Episode =  407, reward =  36.000 (best reward= 172.216), step=4967 agent_position = ( -0.588,  0.389,  0.000) 
Episode =  408, reward =  36.000 (best reward= 172.216), step=4979 agent_position = ( -0.591,  0.386,  0.000) 
Episode =  409, reward =  36.000 (best reward= 172.216), step=4991 agent_position = ( -0.605,  0.406,  0.000) 
Episode =  410, reward =  39.000 (best reward= 172.216), step=5004 agent_position = ( -0.488,  0.461,  0.000) 
Episode =  411, reward =  36.000 (best reward= 172.216), step=5016 agent_position = ( -0.612,  0.402,  0.000) 
Episode =  412, reward =  39.000 (best reward= 172.216), step=5029 agent_position = ( -0.480,  0.419,  0.000) 
Episode =  413, reward =  36.000 (best reward= 172.216), step=5041 agent_position = ( -0.595,  0.344,  0.000) 
Episode =  414, reward =  36.000 (best reward= 172.216), step=5053 agent_position = ( -0.591,  0.394,  0.000) 
Episode =  415, reward =  36.000 (best reward= 172.216), step=5065 agent_position = ( -0.516,  0.348,  0.000) 
Episode =  416, reward =  36.000 (best reward= 172.216), step=5077 agent_position = ( -0.594,  0.358,  0.000) 
Episode =  417, reward =  36.000 (best reward= 172.216), step=5089 agent_position = ( -0.870, -0.415,  0.000) 
Episode =  418, reward =  42.000 (best reward= 172.216), step=5103 agent_position = ( -1.012,  0.402,  0.000) 
Episode =  419, reward =  42.000 (best reward= 172.216), step=5117 agent_position = ( -1.135,  0.934,  0.000) 
Episode =  420, reward =  45.000 (best reward= 172.216), step=5132 agent_position = ( -0.933, -0.456,  0.000) 
Episode =  421, reward =  42.000 (best reward= 172.216), step=5146 agent_position = ( -0.861, -0.391,  0.000) 
Episode =  422, reward =  36.000 (best reward= 172.216), step=5158 agent_position = ( -0.638,  0.323,  0.000) 
Episode =  423, reward =  45.000 (best reward= 172.216), step=5173 agent_position = ( -0.800,  0.650,  0.000) 
Episode =  424, reward =  39.000 (best reward= 172.216), step=5186 agent_position = ( -0.500,  0.319,  0.000) 
Episode =  425, reward =  36.000 (best reward= 172.216), step=5198 agent_position = ( -0.583,  0.376,  0.000) 
Episode =  426, reward =  36.000 (best reward= 172.216), step=5210 agent_position = ( -0.591,  0.354,  0.000) 
Episode =  427, reward =  36.000 (best reward= 172.216), step=5222 agent_position = ( -0.597,  0.385,  0.000) 
Episode =  428, reward =  36.000 (best reward= 172.216), step=5234 agent_position = ( -0.601,  0.402,  0.000) 
Episode =  429, reward =  36.000 (best reward= 172.216), step=5246 agent_position = ( -0.510,  0.298,  0.000) 
Episode =  430, reward =  42.000 (best reward= 172.216), step=5260 agent_position = ( -0.590,  0.826,  0.000) 
Episode =  431, reward =  36.000 (best reward= 172.216), step=5272 agent_position = ( -0.515,  0.377,  0.000) 
Episode =  432, reward =  39.000 (best reward= 172.216), step=5285 agent_position = ( -0.496,  0.459,  0.000) 
Episode =  433, reward =  36.000 (best reward= 172.216), step=5297 agent_position = ( -0.600,  0.401,  0.000) 
Episode =  434, reward =  39.000 (best reward= 172.216), step=5310 agent_position = ( -0.484,  0.454,  0.000) 
Episode =  435, reward =  36.000 (best reward= 172.216), step=5322 agent_position = ( -0.598,  0.392,  0.000) 
Episode =  436, reward =  36.000 (best reward= 172.216), step=5334 agent_position = ( -0.527,  0.320,  0.000) 
Episode =  437, reward =  36.000 (best reward= 172.216), step=5346 agent_position = ( -0.585,  0.371,  0.000) 
Episode =  438, reward =  39.000 (best reward= 172.216), step=5359 agent_position = ( -0.953,  0.209,  0.000) 
Episode =  439, reward =  36.000 (best reward= 172.216), step=5371 agent_position = ( -0.607,  0.415,  0.000) 
Episode =  440, reward =  36.000 (best reward= 172.216), step=5383 agent_position = ( -0.603,  0.409,  0.000) 
Episode =  441, reward =  39.000 (best reward= 172.216), step=5396 agent_position = ( -0.620,  0.686,  0.000) 
Episode =  442, reward =  48.000 (best reward= 172.216), step=5412 agent_position = ( -0.430,  1.680,  0.000) 
Episode =  443, reward =  42.000 (best reward= 172.216), step=5426 agent_position = ( -1.132,  0.327,  0.000) 
Episode =  444, reward =  39.000 (best reward= 172.216), step=5439 agent_position = ( -0.601,  0.381,  0.000) 
Episode =  445, reward =  36.000 (best reward= 172.216), step=5451 agent_position = ( -0.844, -0.022,  0.000) 
Episode =  446, reward =  36.000 (best reward= 172.216), step=5463 agent_position = ( -0.865,  0.022,  0.000) 
Episode =  447, reward =  36.000 (best reward= 172.216), step=5475 agent_position = ( -0.856,  0.026,  0.000) 
Episode =  448, reward =  39.000 (best reward= 172.216), step=5488 agent_position = ( -1.049,  0.866,  0.000) 
Episode =  449, reward =  36.000 (best reward= 172.216), step=5500 agent_position = ( -0.843,  0.026,  0.000) 
Episode =  450, reward =  36.000 (best reward= 172.216), step=5512 agent_position = ( -0.832,  0.025,  0.000) 
Episode =  451, reward =  36.000 (best reward= 172.216), step=5524 agent_position = ( -0.852,  0.017,  0.000) 
Episode =  452, reward =  36.000 (best reward= 172.216), step=5536 agent_position = ( -0.838,  0.025,  0.000) 
Episode =  453, reward =  36.000 (best reward= 172.216), step=5548 agent_position = ( -0.850,  0.030,  0.000) 
Episode =  454, reward =  36.000 (best reward= 172.216), step=5560 agent_position = ( -0.587,  0.373,  0.000) 
Episode =  455, reward =  45.000 (best reward= 172.216), step=5575 agent_position = ( -0.688, -0.246,  0.000) 
Episode =  456, reward =  36.000 (best reward= 172.216), step=5587 agent_position = ( -0.870,  0.019,  0.000) 
Episode =  457, reward =  36.000 (best reward= 172.216), step=5599 agent_position = ( -0.867, -0.004,  0.000) 
Episode =  458, reward =  36.000 (best reward= 172.216), step=5611 agent_position = ( -0.861,  0.008,  0.000) 
Episode =  459, reward =  36.000 (best reward= 172.216), step=5623 agent_position = ( -0.857,  0.016,  0.000) 
Episode =  460, reward =  36.000 (best reward= 172.216), step=5635 agent_position = ( -0.854,  0.041,  0.000) 
Episode =  461, reward =  36.000 (best reward= 172.216), step=5647 agent_position = ( -0.850,  0.049,  0.000) 
Episode =  462, reward =  36.000 (best reward= 172.216), step=5659 agent_position = ( -0.828,  0.021,  0.000) 
Episode =  463, reward =  36.000 (best reward= 172.216), step=5671 agent_position = ( -0.740, -0.079,  0.000) 
Episode =  464, reward =  36.000 (best reward= 172.216), step=5683 agent_position = ( -0.858,  0.061,  0.000) 
Episode =  465, reward =  36.000 (best reward= 172.216), step=5695 agent_position = ( -0.841, -0.023,  0.000) 
Episode =  466, reward =  36.000 (best reward= 172.216), step=5707 agent_position = ( -0.842, -0.006,  0.000) 
Episode =  467, reward =  36.000 (best reward= 172.216), step=5719 agent_position = ( -0.859,  0.010,  0.000) 
Episode =  468, reward =  36.000 (best reward= 172.216), step=5731 agent_position = ( -0.859,  0.008,  0.000) 
Episode =  469, reward =  42.000 (best reward= 172.216), step=5745 agent_position = ( -0.782, -0.357,  0.000) 
Episode =  470, reward =  39.000 (best reward= 172.216), step=5758 agent_position = ( -0.609, -0.421,  0.000) 
Episode =  471, reward =  30.000 (best reward= 172.216), step=5768 agent_position = ( -0.737,  0.241,  0.000) 
Episode =  472, reward =  36.000 (best reward= 172.216), step=5780 agent_position = ( -0.516,  0.234,  0.000) 
Episode =  473, reward =  36.000 (best reward= 172.216), step=5792 agent_position = ( -0.601,  0.417,  0.000) 
Episode =  474, reward =  36.000 (best reward= 172.216), step=5804 agent_position = ( -0.513,  0.236,  0.000) 
Episode =  475, reward =  36.000 (best reward= 172.216), step=5816 agent_position = ( -0.597,  0.384,  0.000) 
Episode =  476, reward =  36.000 (best reward= 172.216), step=5828 agent_position = ( -0.519,  0.273,  0.000) 
Episode =  477, reward =  36.000 (best reward= 172.216), step=5840 agent_position = ( -0.553,  0.286,  0.000) 
Episode =  478, reward =  33.000 (best reward= 172.216), step=5851 agent_position = ( -0.744, -0.039,  0.000) 
Episode =  479, reward =  39.000 (best reward= 172.216), step=5864 agent_position = ( -0.894,  0.031,  0.000) 
Episode =  480, reward =  42.000 (best reward= 172.216), step=5878 agent_position = ( -1.228, -0.293,  0.000) 
Episode =  481, reward =  39.000 (best reward= 172.216), step=5891 agent_position = ( -0.904, -0.051,  0.000) 
Episode =  482, reward =  39.000 (best reward= 172.216), step=5904 agent_position = ( -0.902, -0.039,  0.000) 
Episode =  483, reward =  36.000 (best reward= 172.216), step=5916 agent_position = ( -0.805, -0.295,  0.000) 
Episode =  484, reward =  36.000 (best reward= 172.216), step=5928 agent_position = ( -0.853,  0.015,  0.000) 
Episode =  485, reward =  36.000 (best reward= 172.216), step=5940 agent_position = ( -0.852,  0.008,  0.000) 
Episode =  486, reward =  39.000 (best reward= 172.216), step=5953 agent_position = ( -0.891,  0.071,  0.000) 
Episode =  487, reward =  30.000 (best reward= 172.216), step=5963 agent_position = ( -0.632,  0.099,  0.000) 
Episode =  488, reward =  39.000 (best reward= 172.216), step=5976 agent_position = ( -0.937, -0.052,  0.000) 
Episode =  489, reward =  33.000 (best reward= 172.216), step=5987 agent_position = ( -0.720, -0.218,  0.000) 
Episode =  490, reward =  36.000 (best reward= 172.216), step=5999 agent_position = ( -0.952,  0.008,  0.000) 
Episode =  491, reward =  36.000 (best reward= 172.216), step=6011 agent_position = ( -0.849,  0.085,  0.000) 
Episode =  492, reward =  48.000 (best reward= 172.216), step=6027 agent_position = ( -0.895, -0.213,  0.000) 
Episode =  493, reward =  36.000 (best reward= 172.216), step=6039 agent_position = ( -0.834,  0.092,  0.000) 
Episode =  494, reward =  39.000 (best reward= 172.216), step=6052 agent_position = ( -0.933,  0.006,  0.000) 
Episode =  495, reward =  36.000 (best reward= 172.216), step=6064 agent_position = ( -0.845,  0.052,  0.000) 
Episode =  496, reward =  36.000 (best reward= 172.216), step=6076 agent_position = ( -0.858,  0.014,  0.000) 
Episode =  497, reward =  36.000 (best reward= 172.216), step=6088 agent_position = ( -0.860,  0.011,  0.000) 
Episode =  498, reward =  39.000 (best reward= 172.216), step=6101 agent_position = ( -0.900,  0.040,  0.000) 
Episode =  499, reward =  39.000 (best reward= 172.216), step=6114 agent_position = ( -0.920, -0.073,  0.000) 
Episode =  500, reward =  39.000 (best reward= 172.216), step=6127 agent_position = ( -0.896,  0.062,  0.000) 
Episode =  501, reward =  36.000 (best reward= 172.216), step=6139 agent_position = ( -0.867,  0.090,  0.000) 
Episode =  502, reward =  36.000 (best reward= 172.216), step=6151 agent_position = ( -0.897, -0.925,  0.000) 
Episode =  503, reward =  33.000 (best reward= 172.216), step=6162 agent_position = ( -0.767,  0.278,  0.000) 
Episode =  504, reward =  42.000 (best reward= 172.216), step=6176 agent_position = ( -0.713, -0.612,  0.000) 
Episode =  505, reward =  36.000 (best reward= 172.216), step=6188 agent_position = ( -0.858,  0.079,  0.000) 
Episode =  506, reward =  39.000 (best reward= 172.216), step=6201 agent_position = ( -0.780, -0.362,  0.000) 
Episode =  507, reward =  39.000 (best reward= 172.216), step=6214 agent_position = ( -0.919, -0.036,  0.000) 
Episode =  508, reward =  36.000 (best reward= 172.216), step=6226 agent_position = ( -0.854,  0.015,  0.000) 
Episode =  509, reward =  36.000 (best reward= 172.216), step=6238 agent_position = ( -0.848,  0.007,  0.000) 
Episode =  510, reward =  39.000 (best reward= 172.216), step=6251 agent_position = ( -0.871, -0.210,  0.000) 
Episode =  511, reward =  36.000 (best reward= 172.216), step=6263 agent_position = ( -0.835,  0.037,  0.000) 
Episode =  512, reward =  51.000 (best reward= 172.216), step=6280 agent_position = ( -0.750, -0.090,  0.000) 
Episode =  513, reward =  45.000 (best reward= 172.216), step=6295 agent_position = ( -0.486,  0.153,  0.000) 
Episode =  514, reward =  36.000 (best reward= 172.216), step=6307 agent_position = ( -0.820, -0.000,  0.000) 
Episode =  515, reward =  45.000 (best reward= 172.216), step=6322 agent_position = ( -0.767, -0.261,  0.000) 
Episode =  516, reward =  39.000 (best reward= 172.216), step=6335 agent_position = ( -0.859,  0.027,  0.000) 
Episode =  517, reward =  39.000 (best reward= 172.216), step=6348 agent_position = ( -0.913, -0.043,  0.000) 
Episode =  518, reward =  39.000 (best reward= 172.216), step=6361 agent_position = ( -0.683,  0.340,  0.000) 
Episode =  519, reward =  39.000 (best reward= 172.216), step=6374 agent_position = ( -0.937, -0.063,  0.000) 
Episode =  520, reward =  39.000 (best reward= 172.216), step=6387 agent_position = ( -0.903, -0.155,  0.000) 
Episode =  521, reward =  39.000 (best reward= 172.216), step=6400 agent_position = ( -0.922,  0.027,  0.000) 
Episode =  522, reward =  36.000 (best reward= 172.216), step=6412 agent_position = ( -0.841,  0.008,  0.000) 
Episode =  523, reward =  39.000 (best reward= 172.216), step=6425 agent_position = ( -0.901, -0.057,  0.000) 
Episode =  524, reward =  36.000 (best reward= 172.216), step=6437 agent_position = ( -0.858,  0.006,  0.000) 
Episode =  525, reward =  36.000 (best reward= 172.216), step=6449 agent_position = ( -0.875,  0.005,  0.000) 
Episode =  526, reward =  36.000 (best reward= 172.216), step=6461 agent_position = ( -0.832, -0.000,  0.000) 
Episode =  527, reward =  36.000 (best reward= 172.216), step=6473 agent_position = ( -0.870,  0.055,  0.000) 
Episode =  528, reward =  39.000 (best reward= 172.216), step=6486 agent_position = ( -0.886, -0.060,  0.000) 
Episode =  529, reward =  36.000 (best reward= 172.216), step=6498 agent_position = ( -0.865,  0.005,  0.000) 
Episode =  530, reward =  45.000 (best reward= 172.216), step=6513 agent_position = ( -1.358,  0.174,  0.000) 
Episode =  531, reward =  42.000 (best reward= 172.216), step=6527 agent_position = ( -1.217,  0.723,  0.000) 
Episode =  532, reward =  33.000 (best reward= 172.216), step=6538 agent_position = ( -1.052, -0.558,  0.000) 
Episode =  533, reward =  39.000 (best reward= 172.216), step=6551 agent_position = ( -0.910,  0.016,  0.000) 
Episode =  534, reward =  39.000 (best reward= 172.216), step=6564 agent_position = ( -0.785, -0.911,  0.000) 
Episode =  535, reward =  42.000 (best reward= 172.216), step=6578 agent_position = ( -0.758, -0.369,  0.000) 
Episode =  536, reward =  45.000 (best reward= 172.216), step=6593 agent_position = ( -0.740,  0.588,  0.000) 
Episode =  537, reward =  36.000 (best reward= 172.216), step=6605 agent_position = ( -0.801, -0.005,  0.000) 
Episode =  538, reward =  36.000 (best reward= 172.216), step=6617 agent_position = ( -0.799, -0.006,  0.000) 
Episode =  539, reward =  36.000 (best reward= 172.216), step=6629 agent_position = ( -0.785, -0.012,  0.000) 
Episode =  540, reward =  36.000 (best reward= 172.216), step=6641 agent_position = ( -0.766, -0.005,  0.000) 
Episode =  541, reward =  39.000 (best reward= 172.216), step=6654 agent_position = ( -0.909, -0.058,  0.000) 
Episode =  542, reward =  36.000 (best reward= 172.216), step=6666 agent_position = ( -0.783, -0.018,  0.000) 
Episode =  543, reward =  36.000 (best reward= 172.216), step=6678 agent_position = ( -0.754, -0.018,  0.000) 
Episode =  544, reward =  36.000 (best reward= 172.216), step=6690 agent_position = ( -0.789, -0.013,  0.000) 
Episode =  545, reward =  36.000 (best reward= 172.216), step=6702 agent_position = ( -0.782, -0.024,  0.000) 
Episode =  546, reward =  39.000 (best reward= 172.216), step=6715 agent_position = ( -0.901, -0.007,  0.000) 
Episode =  547, reward =  36.000 (best reward= 172.216), step=6727 agent_position = ( -0.804, -0.016,  0.000) 
Episode =  548, reward =  36.000 (best reward= 172.216), step=6739 agent_position = ( -0.783, -0.013,  0.000) 
Episode =  549, reward =  36.000 (best reward= 172.216), step=6751 agent_position = ( -0.792, -0.009,  0.000) 
Episode =  550, reward =  36.000 (best reward= 172.216), step=6763 agent_position = ( -0.707, -0.238,  0.000) 
Episode =  551, reward =  39.000 (best reward= 172.216), step=6776 agent_position = ( -0.906, -0.061,  0.000) 
Episode =  552, reward =  39.000 (best reward= 172.216), step=6789 agent_position = ( -0.868, -0.067,  0.000) 
Episode =  553, reward =  36.000 (best reward= 172.216), step=6801 agent_position = ( -0.694, -0.026,  0.000) 
Episode =  554, reward =  39.000 (best reward= 172.216), step=6814 agent_position = ( -0.896, -0.065,  0.000) 
Episode =  555, reward =  36.000 (best reward= 172.216), step=6826 agent_position = ( -0.982,  0.079,  0.000) 
Episode =  556, reward =  39.000 (best reward= 172.216), step=6839 agent_position = ( -0.916, -0.062,  0.000) 
Episode =  557, reward =  39.000 (best reward= 172.216), step=6852 agent_position = ( -1.725,  0.170,  0.000) 
Episode =  558, reward =  39.000 (best reward= 172.216), step=6865 agent_position = ( -1.863,  0.320,  0.000) 
Episode =  559, reward =  48.000 (best reward= 172.216), step=6881 agent_position = ( -2.632,  0.556,  0.000) 
Episode =  560, reward =  39.000 (best reward= 172.216), step=6894 agent_position = ( -1.897,  0.113,  0.000) 
Episode =  561, reward =  36.000 (best reward= 172.216), step=6906 agent_position = ( -1.862, -0.257,  0.000) 
Episode =  562, reward =  39.000 (best reward= 172.216), step=6919 agent_position = ( -0.905, -0.060,  0.000) 
Episode =  563, reward =  39.000 (best reward= 172.216), step=6932 agent_position = ( -0.896, -0.060,  0.000) 
Episode =  564, reward =  39.000 (best reward= 172.216), step=6945 agent_position = ( -1.923,  0.134,  0.000) 
Episode =  565, reward =  36.000 (best reward= 172.216), step=6957 agent_position = ( -1.804,  0.515,  0.000) 
Episode =  566, reward =  39.000 (best reward= 172.216), step=6970 agent_position = ( -1.958,  0.184,  0.000) 
Episode =  567, reward =  36.000 (best reward= 172.216), step=6982 agent_position = ( -1.911,  0.422,  0.000) 
Episode =  568, reward =  39.000 (best reward= 172.216), step=6995 agent_position = ( -0.906, -0.061,  0.000) 
Episode =  569, reward =  39.000 (best reward= 172.216), step=7008 agent_position = ( -0.920, -0.059,  0.000) 
Episode =  570, reward =  39.000 (best reward= 172.216), step=7021 agent_position = ( -0.916, -0.053,  0.000) 
Episode =  571, reward =  33.000 (best reward= 172.216), step=7032 agent_position = ( -1.846, -0.310,  0.000) 
Episode =  572, reward =  39.000 (best reward= 172.216), step=7045 agent_position = ( -0.921, -0.063,  0.000) 
Episode =  573, reward =  39.000 (best reward= 172.216), step=7058 agent_position = ( -2.095,  0.399,  0.000) 
Episode =  574, reward =  39.000 (best reward= 172.216), step=7071 agent_position = ( -2.115,  0.313,  0.000) 
Episode =  575, reward =  42.000 (best reward= 172.216), step=7085 agent_position = ( -2.225,  0.547,  0.000) 
Episode =  576, reward =  39.000 (best reward= 172.216), step=7098 agent_position = ( -0.898, -0.062,  0.000) 
Episode =  577, reward =  39.000 (best reward= 172.216), step=7111 agent_position = ( -2.161,  0.214,  0.000) 
Episode =  578, reward =  39.000 (best reward= 172.216), step=7124 agent_position = ( -2.057,  0.441,  0.000) 
Episode =  579, reward =  39.000 (best reward= 172.216), step=7137 agent_position = ( -0.888, -0.067,  0.000) 
Episode =  580, reward =  39.000 (best reward= 172.216), step=7150 agent_position = ( -2.129,  0.232,  0.000) 
Episode =  581, reward =  42.000 (best reward= 172.216), step=7164 agent_position = ( -2.270,  0.028,  0.000) 
Episode =  582, reward =  39.000 (best reward= 172.216), step=7177 agent_position = ( -1.919,  0.094,  0.000) 
Episode =  583, reward =  39.000 (best reward= 172.216), step=7190 agent_position = ( -0.881, -0.065,  0.000) 
Episode =  584, reward =  39.000 (best reward= 172.216), step=7203 agent_position = ( -1.968,  0.098,  0.000) 
Episode =  585, reward =  33.000 (best reward= 172.216), step=7214 agent_position = ( -1.757,  0.334,  0.000) 
Episode =  586, reward =  39.000 (best reward= 172.216), step=7227 agent_position = ( -2.189,  0.084,  0.000) 
Episode =  587, reward =  39.000 (best reward= 172.216), step=7240 agent_position = ( -2.156,  0.178,  0.000) 
Episode =  588, reward =  39.000 (best reward= 172.216), step=7253 agent_position = ( -0.873, -0.063,  0.000) 
Episode =  589, reward =  39.000 (best reward= 172.216), step=7266 agent_position = ( -0.926, -0.059,  0.000) 
Episode =  590, reward =  39.000 (best reward= 172.216), step=7279 agent_position = ( -2.156,  0.129,  0.000) 
Episode =  591, reward =  39.000 (best reward= 172.216), step=7292 agent_position = ( -0.907, -0.058,  0.000) 
Episode =  592, reward =  42.000 (best reward= 172.216), step=7306 agent_position = ( -1.250,  0.531,  0.000) 
Episode =  593, reward =  42.000 (best reward= 172.216), step=7320 agent_position = ( -1.166,  0.691,  0.000) 
Episode =  594, reward =  39.000 (best reward= 172.216), step=7333 agent_position = ( -2.178,  0.166,  0.000) 
Episode =  595, reward =  39.000 (best reward= 172.216), step=7346 agent_position = ( -2.095,  0.059,  0.000) 
Episode =  596, reward =  39.000 (best reward= 172.216), step=7359 agent_position = ( -0.903, -0.059,  0.000) 
Episode =  597, reward =  39.000 (best reward= 172.216), step=7372 agent_position = ( -0.904, -0.061,  0.000) 
Episode =  598, reward =  39.000 (best reward= 172.216), step=7385 agent_position = ( -0.896, -0.060,  0.000) 
Episode =  599, reward =  33.000 (best reward= 172.216), step=7396 agent_position = ( -1.813,  0.040,  0.000) 
Episode =  600, reward =  33.000 (best reward= 172.216), step=7407 agent_position = ( -1.775,  0.268,  0.000) 
Episode =  601, reward =  39.000 (best reward= 172.216), step=7420 agent_position = ( -1.935,  0.102,  0.000) 
Episode =  602, reward =  39.000 (best reward= 172.216), step=7433 agent_position = ( -0.883, -0.066,  0.000) 
Episode =  603, reward =  39.000 (best reward= 172.216), step=7446 agent_position = ( -2.156,  0.178,  0.000) 
Episode =  604, reward =  39.000 (best reward= 172.216), step=7459 agent_position = ( -2.171,  0.148,  0.000) 
Episode =  605, reward =  39.000 (best reward= 172.216), step=7472 agent_position = ( -0.919, -0.060,  0.000) 
Episode =  606, reward =  39.000 (best reward= 172.216), step=7485 agent_position = ( -0.909, -0.062,  0.000) 
Episode =  607, reward =  39.000 (best reward= 172.216), step=7498 agent_position = ( -1.951,  0.112,  0.000) 
Episode =  608, reward =  39.000 (best reward= 172.216), step=7511 agent_position = ( -1.984,  0.158,  0.000) 
Episode =  609, reward =  39.000 (best reward= 172.216), step=7524 agent_position = ( -1.915,  0.096,  0.000) 
Episode =  610, reward =  39.000 (best reward= 172.216), step=7537 agent_position = ( -1.938,  0.104,  0.000) 
Episode =  611, reward =  39.000 (best reward= 172.216), step=7550 agent_position = ( -0.890,  0.141,  0.000) 
Episode =  612, reward =  39.000 (best reward= 172.216), step=7563 agent_position = ( -1.965,  0.108,  0.000) 
Episode =  613, reward =  39.000 (best reward= 172.216), step=7576 agent_position = ( -2.013,  0.254,  0.000) 
Episode =  614, reward =  39.000 (best reward= 172.216), step=7589 agent_position = ( -0.879,  0.002,  0.000) 
Episode =  615, reward =  39.000 (best reward= 172.216), step=7602 agent_position = ( -1.956,  0.132,  0.000) 
Episode =  616, reward =  39.000 (best reward= 172.216), step=7615 agent_position = ( -1.920,  0.134,  0.000) 
Episode =  617, reward =  39.000 (best reward= 172.216), step=7628 agent_position = ( -1.977,  0.100,  0.000) 
Episode =  618, reward =  39.000 (best reward= 172.216), step=7641 agent_position = ( -1.955,  0.112,  0.000) 
Episode =  619, reward =  39.000 (best reward= 172.216), step=7654 agent_position = ( -0.865,  0.001,  0.000) 
Episode =  620, reward =  39.000 (best reward= 172.216), step=7667 agent_position = ( -1.917,  0.141,  0.000) 
Episode =  621, reward =  42.000 (best reward= 172.216), step=7681 agent_position = ( -0.579,  0.412,  0.000) 
Episode =  622, reward =  39.000 (best reward= 172.216), step=7694 agent_position = ( -0.894, -0.083,  0.000) 
Episode =  623, reward =  39.000 (best reward= 172.216), step=7707 agent_position = ( -0.875,  0.000,  0.000) 
Episode =  624, reward =  39.000 (best reward= 172.216), step=7720 agent_position = ( -0.899,  0.001,  0.000) 
Episode =  625, reward =  39.000 (best reward= 172.216), step=7733 agent_position = ( -0.884, -0.000,  0.000) 
Episode =  626, reward =  39.000 (best reward= 172.216), step=7746 agent_position = ( -0.863,  0.001,  0.000) 
Episode =  627, reward =  39.000 (best reward= 172.216), step=7759 agent_position = ( -1.913,  0.133,  0.000) 
Episode =  628, reward =  39.000 (best reward= 172.216), step=7772 agent_position = ( -1.924,  0.134,  0.000) 
Episode =  629, reward =  39.000 (best reward= 172.216), step=7785 agent_position = ( -1.902,  0.154,  0.000) 
Episode =  630, reward =  39.000 (best reward= 172.216), step=7798 agent_position = ( -1.050,  0.221,  0.000) 
Episode =  631, reward =  39.000 (best reward= 172.216), step=7811 agent_position = ( -0.850,  0.003,  0.000) 
Episode =  632, reward =  39.000 (best reward= 172.216), step=7824 agent_position = ( -0.910, -0.026,  0.000) 
Episode =  633, reward =  39.000 (best reward= 172.216), step=7837 agent_position = ( -1.899,  0.135,  0.000) 
Episode =  634, reward =  39.000 (best reward= 172.216), step=7850 agent_position = ( -1.941,  0.115,  0.000) 
Episode =  635, reward =  42.000 (best reward= 172.216), step=7864 agent_position = ( -0.618, -0.595,  0.000) 
Episode =  636, reward =  39.000 (best reward= 172.216), step=7877 agent_position = ( -1.929,  0.142,  0.000) 
Episode =  637, reward =  39.000 (best reward= 172.216), step=7890 agent_position = ( -1.905,  0.148,  0.000) 
Episode =  638, reward =  39.000 (best reward= 172.216), step=7903 agent_position = ( -1.949,  0.126,  0.000) 
Episode =  639, reward =  39.000 (best reward= 172.216), step=7916 agent_position = ( -0.855,  0.001,  0.000) 
Episode =  640, reward =  42.000 (best reward= 172.216), step=7930 agent_position = ( -0.630, -0.193,  0.000) 
Episode =  641, reward =  39.000 (best reward= 172.216), step=7943 agent_position = ( -0.885,  0.001,  0.000) 
Episode =  642, reward =  39.000 (best reward= 172.216), step=7956 agent_position = ( -1.909,  0.142,  0.000) 
Episode =  643, reward =  39.000 (best reward= 172.216), step=7969 agent_position = ( -0.870,  0.000,  0.000) 
Episode =  644, reward =  39.000 (best reward= 172.216), step=7982 agent_position = ( -1.930,  0.122,  0.000) 
Episode =  645, reward =  42.000 (best reward= 172.216), step=7996 agent_position = ( -1.126,  0.233,  0.000) 
Episode =  646, reward =  39.000 (best reward= 172.216), step=8009 agent_position = ( -1.950,  0.139,  0.000) 
Episode =  647, reward =  39.000 (best reward= 172.216), step=8022 agent_position = ( -1.901,  0.131,  0.000) 
Episode =  648, reward =  39.000 (best reward= 172.216), step=8035 agent_position = ( -0.892,  0.006,  0.000) 
Episode =  649, reward =  39.000 (best reward= 172.216), step=8048 agent_position = ( -0.869,  0.002,  0.000) 
Episode =  650, reward =  42.000 (best reward= 172.216), step=8062 agent_position = ( -1.124,  0.200,  0.000) 
Episode =  651, reward =  39.000 (best reward= 172.216), step=8075 agent_position = ( -1.922,  0.130,  0.000) 
Episode =  652, reward =  39.000 (best reward= 172.216), step=8088 agent_position = ( -0.895,  0.001,  0.000) 
Episode =  653, reward =  39.000 (best reward= 172.216), step=8101 agent_position = ( -1.894,  0.359,  0.000) 
Episode =  654, reward =  36.000 (best reward= 172.216), step=8113 agent_position = ( -2.479, -0.064,  0.000) 
Episode =  655, reward =  39.000 (best reward= 172.216), step=8126 agent_position = ( -1.941,  0.123,  0.000) 
Episode =  656, reward =  39.000 (best reward= 172.216), step=8139 agent_position = ( -1.932,  0.151,  0.000) 
Episode =  657, reward =  39.000 (best reward= 172.216), step=8152 agent_position = ( -0.883,  0.002,  0.000) 
Episode =  658, reward =  39.000 (best reward= 172.216), step=8165 agent_position = ( -0.879,  0.001,  0.000) 
Episode =  659, reward =  39.000 (best reward= 172.216), step=8178 agent_position = ( -1.836,  0.134,  0.000) 
Episode =  660, reward =  39.000 (best reward= 172.216), step=8191 agent_position = ( -1.897,  0.139,  0.000) 
Episode =  661, reward =  36.000 (best reward= 172.216), step=8203 agent_position = ( -1.640, -0.179,  0.000) 
Episode =  662, reward =  36.000 (best reward= 172.216), step=8215 agent_position = ( -2.602, -0.109,  0.000) 
Episode =  663, reward =  33.000 (best reward= 172.216), step=8226 agent_position = ( -2.281, -0.190,  0.000) 
Episode =  664, reward =  33.000 (best reward= 172.216), step=8237 agent_position = ( -2.264, -0.215,  0.000) 
Episode =  665, reward =  33.000 (best reward= 172.216), step=8248 agent_position = ( -2.273, -0.209,  0.000) 
Episode =  666, reward =  39.000 (best reward= 172.216), step=8261 agent_position = ( -0.864,  0.078,  0.000) 
Episode =  667, reward =  39.000 (best reward= 172.216), step=8274 agent_position = ( -2.360,  0.000,  0.000) 
Episode =  668, reward =  39.000 (best reward= 172.216), step=8287 agent_position = ( -0.894,  0.001,  0.000) 
Episode =  669, reward =  39.000 (best reward= 172.216), step=8300 agent_position = ( -0.862,  0.002,  0.000) 
Episode =  670, reward =  33.000 (best reward= 172.216), step=8311 agent_position = ( -2.321, -0.177,  0.000) 
Episode =  671, reward =  39.000 (best reward= 172.216), step=8324 agent_position = ( -0.646, -0.038,  0.000) 
Episode =  672, reward =  39.000 (best reward= 172.216), step=8337 agent_position = ( -0.881,  0.000,  0.000) 
Episode =  673, reward =  36.000 (best reward= 172.216), step=8349 agent_position = ( -2.477, -0.244,  0.000) 
Episode =  674, reward =  39.000 (best reward= 172.216), step=8362 agent_position = ( -0.860,  0.003,  0.000) 
Episode =  675, reward =  42.000 (best reward= 172.216), step=8376 agent_position = ( -0.573, -0.478,  0.000) 
Episode =  676, reward =  42.000 (best reward= 172.216), step=8390 agent_position = ( -0.581, -0.255,  0.000) 
Episode =  677, reward =  33.000 (best reward= 172.216), step=8401 agent_position = ( -1.074, -0.606,  0.000) 
Episode =  678, reward = 252.000 (best reward= 252.000), step=8485 agent_position = ( -3.429,  1.855, 27.969) 
Episode =  679, reward = 252.000 (best reward= 252.000), step=8569 agent_position = ( -3.465, -9.264, 27.392) 
Episode =  680, reward = 252.000 (best reward= 252.000), step=8653 agent_position = ( -3.310,  4.962, 27.986) 
Episode =  681, reward = 252.000 (best reward= 252.000), step=8737 agent_position = ( -3.222,  5.175, 28.175) 
Episode =  682, reward = 252.000 (best reward= 252.000), step=8821 agent_position = ( -3.274,  3.761, 28.144) 
Episode =  683, reward = 252.000 (best reward= 252.000), step=8905 agent_position = ( -3.302,  1.161, 28.182) 
Episode =  684, reward =  27.000 (best reward= 252.000), step=8914 agent_position = ( -0.659,  0.524,  0.000) 
Episode =  685, reward =  24.000 (best reward= 252.000), step=8922 agent_position = (  0.509, -0.387,  0.000) 
Episode =  686, reward =  30.000 (best reward= 252.000), step=8932 agent_position = ( -1.623, -0.344,  0.000) 
Episode =  687, reward =  36.000 (best reward= 252.000), step=8944 agent_position = (  1.193, -0.134,  0.000) 
Episode =  688, reward =  39.000 (best reward= 252.000), step=8957 agent_position = ( -1.760, -0.836,  0.000) 
Episode =  689, reward =  42.000 (best reward= 252.000), step=8971 agent_position = ( -1.584,  0.071,  0.000) 
Episode =  690, reward =  24.000 (best reward= 252.000), step=8979 agent_position = ( -0.184, -0.311,  0.000) 
Episode =  691, reward =  30.000 (best reward= 252.000), step=8989 agent_position = (  1.335, -0.353,  0.000) 
Episode =  692, reward =  39.000 (best reward= 252.000), step=9002 agent_position = ( -1.425,  1.358,  0.000) 
Episode =  693, reward =  36.000 (best reward= 252.000), step=9014 agent_position = ( -1.893,  0.241,  0.000) 
Episode =  694, reward =  57.000 (best reward= 252.000), step=9033 agent_position = ( -0.710,  0.286,  0.000) 
Episode =  695, reward =  36.000 (best reward= 252.000), step=9045 agent_position = ( -0.636, -0.155,  0.000) 
Episode =  696, reward =  33.000 (best reward= 252.000), step=9056 agent_position = ( -0.930,  0.096,  0.000) 
Episode =  697, reward =  42.000 (best reward= 252.000), step=9070 agent_position = ( -1.576,  0.139,  0.000) 
Episode =  698, reward =  39.000 (best reward= 252.000), step=9083 agent_position = ( -0.795,  0.569,  0.000) 
Episode =  699, reward =  30.000 (best reward= 252.000), step=9093 agent_position = ( -1.276, -0.258,  0.000) 
Episode =  700, reward =  45.000 (best reward= 252.000), step=9108 agent_position = ( -2.479,  0.173,  0.000) 
Episode =  701, reward =  27.000 (best reward= 252.000), step=9117 agent_position = ( -0.312, -0.925,  0.000) 
Episode =  702, reward =  24.000 (best reward= 252.000), step=9125 agent_position = ( -0.336, -0.045,  0.000) 
Episode =  703, reward =  33.000 (best reward= 252.000), step=9136 agent_position = ( -0.568,  0.585,  0.000) 
Episode =  704, reward =  30.000 (best reward= 252.000), step=9146 agent_position = ( -0.494,  0.209,  0.000) 
Episode =  705, reward = 252.000 (best reward= 252.000), step=9230 agent_position = ( -3.160, -9.436, 27.634) 
Episode =  706, reward = 252.000 (best reward= 252.000), step=9314 agent_position = ( -3.228,  9.095, 27.859) 
Episode =  707, reward = 252.000 (best reward= 252.000), step=9398 agent_position = ( -3.298,  0.144, 28.135) 
Episode =  708, reward =  30.000 (best reward= 252.000), step=9408 agent_position = ( -0.850,  0.277,  0.000) 
Episode =  709, reward =  27.000 (best reward= 252.000), step=9417 agent_position = ( -0.623,  0.467,  0.000) 
Episode =  710, reward =  30.000 (best reward= 252.000), step=9427 agent_position = ( -0.742,  0.316,  0.000) 
Episode =  711, reward =  30.000 (best reward= 252.000), step=9437 agent_position = ( -0.814,  0.307,  0.000) 
Episode =  712, reward =  27.000 (best reward= 252.000), step=9446 agent_position = ( -0.361,  0.530,  0.000) 
Episode =  713, reward =  30.000 (best reward= 252.000), step=9456 agent_position = ( -0.226,  0.348,  0.000) 
Episode =  714, reward =  30.000 (best reward= 252.000), step=9466 agent_position = (  1.015,  0.276,  0.000) 
Episode =  715, reward =  33.000 (best reward= 252.000), step=9477 agent_position = ( -0.495,  0.595,  0.000) 
Episode =  716, reward =  27.000 (best reward= 252.000), step=9486 agent_position = ( -0.808,  0.329,  0.000) 
Episode =  717, reward =  30.000 (best reward= 252.000), step=9496 agent_position = (  0.521,  0.270,  0.000) 
Episode =  718, reward =  33.000 (best reward= 252.000), step=9507 agent_position = ( -0.480,  0.451,  0.000) 
Episode =  719, reward =  30.000 (best reward= 252.000), step=9517 agent_position = ( -0.720,  0.343,  0.000) 
Episode =  720, reward =  33.000 (best reward= 252.000), step=9528 agent_position = ( -0.083,  0.306,  0.000) 
Episode =  721, reward =  30.000 (best reward= 252.000), step=9538 agent_position = ( -0.078,  0.297,  0.000) 
Episode =  722, reward =  30.000 (best reward= 252.000), step=9548 agent_position = ( -0.385,  0.133,  0.000) 
Episode =  723, reward =  30.000 (best reward= 252.000), step=9558 agent_position = ( -0.369,  0.340,  0.000) 
Episode =  724, reward =  30.000 (best reward= 252.000), step=9568 agent_position = ( -0.272,  0.294,  0.000) 
Episode =  725, reward =  39.000 (best reward= 252.000), step=9581 agent_position = ( -0.074,  0.002,  0.000) 
Episode =  726, reward =  30.000 (best reward= 252.000), step=9591 agent_position = ( -0.417,  0.201,  0.000) 
Episode =  727, reward =  33.000 (best reward= 252.000), step=9602 agent_position = ( -0.226,  0.275,  0.000) 
Episode =  728, reward =  30.000 (best reward= 252.000), step=9612 agent_position = ( -0.329,  0.298,  0.000) 
Episode =  729, reward =  30.000 (best reward= 252.000), step=9622 agent_position = ( -0.283,  0.320,  0.000) 
Episode =  730, reward =  27.000 (best reward= 252.000), step=9631 agent_position = ( -0.348,  0.224,  0.000) 
Episode =  731, reward =  27.000 (best reward= 252.000), step=9640 agent_position = ( -0.323,  0.497,  0.000) 
Episode =  732, reward =  27.000 (best reward= 252.000), step=9649 agent_position = ( -0.554,  0.430,  0.000) 
Episode =  733, reward =  33.000 (best reward= 252.000), step=9660 agent_position = ( -0.151,  0.135,  0.000) 
Episode =  734, reward =  33.000 (best reward= 252.000), step=9671 agent_position = ( -0.152,  1.038,  0.000) 
Episode =  735, reward =  27.000 (best reward= 252.000), step=9680 agent_position = ( -0.199,  0.517,  0.000) 
Episode =  736, reward =  30.000 (best reward= 252.000), step=9690 agent_position = ( -0.750,  0.161,  0.000) 
Episode =  737, reward =  30.000 (best reward= 252.000), step=9700 agent_position = ( -0.766,  0.120,  0.000) 
Episode =  738, reward =  30.000 (best reward= 252.000), step=9710 agent_position = ( -0.342,  0.065,  0.000) 
Episode =  739, reward =  27.000 (best reward= 252.000), step=9719 agent_position = ( -0.026, -0.107,  0.000) 
Episode =  740, reward =  27.000 (best reward= 252.000), step=9728 agent_position = ( -0.342,  0.224,  0.000) 
Episode =  741, reward =  33.000 (best reward= 252.000), step=9739 agent_position = (  0.500, -0.140,  0.000) 
Episode =  742, reward =  27.000 (best reward= 252.000), step=9748 agent_position = ( -0.187,  0.411,  0.000) 
Episode =  743, reward =  27.000 (best reward= 252.000), step=9757 agent_position = ( -0.183,  0.780,  0.000) 
Episode =  744, reward =  30.000 (best reward= 252.000), step=9767 agent_position = ( -0.101,  0.174,  0.000) 
Episode =  745, reward =  27.000 (best reward= 252.000), step=9776 agent_position = ( -0.164,  0.269,  0.000) 
Episode =  746, reward =  27.000 (best reward= 252.000), step=9785 agent_position = ( -0.114,  0.098,  0.000) 
Episode =  747, reward =  30.000 (best reward= 252.000), step=9795 agent_position = ( -0.482,  0.046,  0.000) 
Episode =  748, reward =  27.000 (best reward= 252.000), step=9804 agent_position = ( -0.007,  0.036,  0.000) 
Episode =  749, reward =  27.000 (best reward= 252.000), step=9813 agent_position = ( -0.233, -0.071,  0.000) 
Episode =  750, reward =  27.000 (best reward= 252.000), step=9822 agent_position = ( -0.417,  0.032,  0.000) 
Episode =  751, reward =  27.000 (best reward= 252.000), step=9831 agent_position = ( -0.071,  0.106,  0.000) 
Episode =  752, reward =  30.000 (best reward= 252.000), step=9841 agent_position = ( -0.497,  0.258,  0.000) 
Episode =  753, reward =  27.000 (best reward= 252.000), step=9850 agent_position = ( -0.414,  0.025,  0.000) 
Episode =  754, reward =  30.000 (best reward= 252.000), step=9860 agent_position = ( -0.438,  0.033,  0.000) 
Episode =  755, reward =  27.000 (best reward= 252.000), step=9869 agent_position = ( -0.157,  0.111,  0.000) 
Episode =  756, reward =  27.000 (best reward= 252.000), step=9878 agent_position = ( -0.349,  0.249,  0.000) 
Episode =  757, reward =  30.000 (best reward= 252.000), step=9888 agent_position = ( -0.051,  0.091,  0.000) 
Episode =  758, reward =  27.000 (best reward= 252.000), step=9897 agent_position = ( -0.307,  0.217,  0.000) 
Episode =  759, reward =  30.000 (best reward= 252.000), step=9907 agent_position = ( -0.182,  0.366,  0.000) 
Episode =  760, reward =  27.000 (best reward= 252.000), step=9916 agent_position = ( -0.316,  0.335,  0.000) 
Episode =  761, reward =  30.000 (best reward= 252.000), step=9926 agent_position = ( -0.191,  0.296,  0.000) 
Episode =  762, reward =  30.000 (best reward= 252.000), step=9936 agent_position = ( -0.164,  0.262,  0.000) 
Episode =  763, reward =  27.000 (best reward= 252.000), step=9945 agent_position = ( -0.394,  0.264,  0.000) 
Episode =  764, reward =  27.000 (best reward= 252.000), step=9954 agent_position = ( -0.089,  0.063,  0.000) 
Episode =  765, reward =  27.000 (best reward= 252.000), step=9963 agent_position = ( -0.287,  0.172,  0.000) 
Episode =  766, reward =  30.000 (best reward= 252.000), step=9973 agent_position = ( -0.193,  0.279,  0.000) 
Episode =  767, reward =  30.000 (best reward= 252.000), step=9983 agent_position = ( -0.249,  0.421,  0.000) 
Episode =  768, reward =  30.000 (best reward= 252.000), step=9993 agent_position = ( -0.498,  0.056,  0.000) 
Episode =  769, reward =  33.000 (best reward= 252.000), step=10004 agent_position = ( -0.450,  0.850,  0.000) 
Episode =  770, reward =  30.000 (best reward= 252.000), step=10014 agent_position = ( -0.268,  0.817,  0.000) 
Episode =  771, reward =  30.000 (best reward= 252.000), step=10024 agent_position = ( -0.419,  0.035,  0.000) 
Episode =  772, reward =  30.000 (best reward= 252.000), step=10034 agent_position = ( -0.450,  0.010,  0.000) 
Episode =  773, reward =  30.000 (best reward= 252.000), step=10044 agent_position = ( -0.393, -0.025,  0.000) 
Episode =  774, reward =  27.000 (best reward= 252.000), step=10053 agent_position = ( -0.167, -0.018,  0.000) 
Episode =  775, reward =  27.000 (best reward= 252.000), step=10062 agent_position = ( -0.278,  0.220,  0.000) 
Episode =  776, reward =  27.000 (best reward= 252.000), step=10071 agent_position = ( -0.426,  0.016,  0.000) 
Episode =  777, reward =  27.000 (best reward= 252.000), step=10080 agent_position = ( -0.401,  0.033,  0.000) 
Episode =  778, reward =  27.000 (best reward= 252.000), step=10089 agent_position = ( -0.425,  0.017,  0.000) 
Episode =  779, reward =  27.000 (best reward= 252.000), step=10098 agent_position = ( -0.349,  0.198,  0.000) 
Episode =  780, reward =  27.000 (best reward= 252.000), step=10107 agent_position = ( -0.391,  0.238,  0.000) 
Episode =  781, reward =  27.000 (best reward= 252.000), step=10116 agent_position = ( -0.327,  0.132,  0.000) 
Episode =  782, reward =  30.000 (best reward= 252.000), step=10126 agent_position = ( -0.372,  0.077,  0.000) 
Episode =  783, reward =  27.000 (best reward= 252.000), step=10135 agent_position = ( -0.100, -0.036,  0.000) 
Episode =  784, reward =  27.000 (best reward= 252.000), step=10144 agent_position = ( -0.240,  0.228,  0.000) 
Episode =  785, reward =  27.000 (best reward= 252.000), step=10153 agent_position = ( -0.267,  0.263,  0.000) 
Episode =  786, reward =  27.000 (best reward= 252.000), step=10162 agent_position = ( -0.121,  0.036,  0.000) 
Episode =  787, reward =  27.000 (best reward= 252.000), step=10171 agent_position = ( -0.403,  0.034,  0.000) 
Episode =  788, reward =  27.000 (best reward= 252.000), step=10180 agent_position = ( -0.392,  0.042,  0.000) 
Episode =  789, reward =  27.000 (best reward= 252.000), step=10189 agent_position = ( -0.390,  0.030,  0.000) 
Episode =  790, reward =  27.000 (best reward= 252.000), step=10198 agent_position = ( -0.398,  0.029,  0.000) 
Episode =  791, reward =  30.000 (best reward= 252.000), step=10208 agent_position = ( -0.203,  0.170,  0.000) 
Episode =  792, reward =  30.000 (best reward= 252.000), step=10218 agent_position = ( -0.329,  0.065,  0.000) 
Episode =  793, reward =  30.000 (best reward= 252.000), step=10228 agent_position = ( -0.355,  0.039,  0.000) 
Episode =  794, reward =  30.000 (best reward= 252.000), step=10238 agent_position = ( -0.308,  0.214,  0.000) 
Episode =  795, reward =  27.000 (best reward= 252.000), step=10247 agent_position = ( -0.253,  0.121,  0.000) 
Episode =  796, reward =  27.000 (best reward= 252.000), step=10256 agent_position = ( -0.401,  0.021,  0.000) 
Episode =  797, reward =  27.000 (best reward= 252.000), step=10265 agent_position = ( -0.391,  0.026,  0.000) 
Episode =  798, reward =  27.000 (best reward= 252.000), step=10274 agent_position = ( -0.388,  0.033,  0.000) 
Episode =  799, reward =  27.000 (best reward= 252.000), step=10283 agent_position = ( -0.425,  0.008,  0.000) 
Episode =  800, reward =  27.000 (best reward= 252.000), step=10292 agent_position = ( -0.341,  0.194,  0.000) 
Episode =  801, reward =  27.000 (best reward= 252.000), step=10301 agent_position = ( -0.329,  0.257,  0.000) 
Episode =  802, reward =  27.000 (best reward= 252.000), step=10310 agent_position = ( -0.425,  0.008,  0.000) 
Episode =  803, reward =  27.000 (best reward= 252.000), step=10319 agent_position = ( -0.408,  0.031,  0.000) 
Episode =  804, reward =  27.000 (best reward= 252.000), step=10328 agent_position = ( -0.442,  0.022,  0.000) 
Episode =  805, reward =  27.000 (best reward= 252.000), step=10337 agent_position = ( -0.347, -0.039,  0.000) 
Episode =  806, reward =  27.000 (best reward= 252.000), step=10346 agent_position = ( -0.416,  0.024,  0.000) 
Episode =  807, reward =  27.000 (best reward= 252.000), step=10355 agent_position = ( -0.423,  0.022,  0.000) 
Episode =  808, reward =  27.000 (best reward= 252.000), step=10364 agent_position = ( -0.410,  0.029,  0.000) 
Episode =  809, reward =  27.000 (best reward= 252.000), step=10373 agent_position = ( -0.439,  0.022,  0.000) 
Episode =  810, reward =  27.000 (best reward= 252.000), step=10382 agent_position = ( -0.464,  0.095,  0.000) 
Episode =  811, reward =  30.000 (best reward= 252.000), step=10392 agent_position = ( -0.504,  0.065,  0.000) 
Episode =  812, reward =  27.000 (best reward= 252.000), step=10401 agent_position = ( -0.418,  0.022,  0.000) 
Episode =  813, reward =  33.000 (best reward= 252.000), step=10412 agent_position = ( -0.123, -0.060,  0.000) 
Episode =  814, reward =  27.000 (best reward= 252.000), step=10421 agent_position = ( -0.348,  0.049,  0.000) 
Episode =  815, reward =  27.000 (best reward= 252.000), step=10430 agent_position = ( -0.408,  0.023,  0.000) 
Episode =  816, reward =  27.000 (best reward= 252.000), step=10439 agent_position = ( -0.403,  0.029,  0.000) 
Episode =  817, reward =  27.000 (best reward= 252.000), step=10448 agent_position = ( -0.422,  0.021,  0.000) 
Episode =  818, reward =  27.000 (best reward= 252.000), step=10457 agent_position = ( -0.432,  0.005,  0.000) 
Episode =  819, reward =  27.000 (best reward= 252.000), step=10466 agent_position = ( -0.414,  0.019,  0.000) 
Episode =  820, reward =  27.000 (best reward= 252.000), step=10475 agent_position = ( -0.420,  0.019,  0.000) 
Episode =  821, reward =  27.000 (best reward= 252.000), step=10484 agent_position = ( -0.414,  0.013,  0.000) 
Episode =  822, reward =  27.000 (best reward= 252.000), step=10493 agent_position = ( -0.424,  0.027,  0.000) 
Episode =  823, reward =  27.000 (best reward= 252.000), step=10502 agent_position = ( -0.445,  0.007,  0.000) 
Episode =  824, reward =  27.000 (best reward= 252.000), step=10511 agent_position = ( -0.424,  0.023,  0.000) 
Episode =  825, reward =  27.000 (best reward= 252.000), step=10520 agent_position = ( -0.433,  0.105,  0.000) 
Episode =  826, reward =  27.000 (best reward= 252.000), step=10529 agent_position = ( -0.418, -0.003,  0.000) 
Episode =  827, reward =  27.000 (best reward= 252.000), step=10538 agent_position = ( -0.416,  0.027,  0.000) 
Episode =  828, reward =  27.000 (best reward= 252.000), step=10547 agent_position = ( -0.416,  0.021,  0.000) 
Episode =  829, reward =  27.000 (best reward= 252.000), step=10556 agent_position = ( -0.404,  0.023,  0.000) 
Episode =  830, reward =  27.000 (best reward= 252.000), step=10565 agent_position = ( -0.398,  0.030,  0.000) 
Episode =  831, reward =  27.000 (best reward= 252.000), step=10574 agent_position = ( -0.418,  0.016,  0.000) 
Episode =  832, reward =  27.000 (best reward= 252.000), step=10583 agent_position = ( -0.091,  0.078,  0.000) 
Episode =  833, reward =  27.000 (best reward= 252.000), step=10592 agent_position = ( -0.423,  0.016,  0.000) 
Episode =  834, reward =  27.000 (best reward= 252.000), step=10601 agent_position = ( -0.416,  0.018,  0.000) 
Episode =  835, reward =  27.000 (best reward= 252.000), step=10610 agent_position = ( -0.413,  0.027,  0.000) 
Episode =  836, reward =  27.000 (best reward= 252.000), step=10619 agent_position = ( -0.076,  0.080,  0.000) 
Episode =  837, reward =  30.000 (best reward= 252.000), step=10629 agent_position = ( -0.297, -0.158,  0.000) 
Episode =  838, reward =  30.000 (best reward= 252.000), step=10639 agent_position = ( -0.357,  0.014,  0.000) 
Episode =  839, reward =  27.000 (best reward= 252.000), step=10648 agent_position = ( -0.412,  0.024,  0.000) 
Episode =  840, reward =  27.000 (best reward= 252.000), step=10657 agent_position = ( -0.360,  0.045,  0.000) 
Episode =  841, reward =  27.000 (best reward= 252.000), step=10666 agent_position = ( -0.402,  0.025,  0.000) 
Episode =  842, reward =  27.000 (best reward= 252.000), step=10675 agent_position = ( -0.421,  0.010,  0.000) 
Episode =  843, reward =  27.000 (best reward= 252.000), step=10684 agent_position = ( -0.399,  0.028,  0.000) 
Episode =  844, reward =  27.000 (best reward= 252.000), step=10693 agent_position = ( -0.404,  0.029,  0.000) 
Episode =  845, reward =  27.000 (best reward= 252.000), step=10702 agent_position = ( -0.421,  0.023,  0.000) 
Episode =  846, reward =  30.000 (best reward= 252.000), step=10712 agent_position = ( -0.488, -0.002,  0.000) 
Episode =  847, reward =  27.000 (best reward= 252.000), step=10721 agent_position = ( -0.478,  0.157,  0.000) 
Episode =  848, reward =  27.000 (best reward= 252.000), step=10730 agent_position = ( -0.422,  0.008,  0.000) 
Episode =  849, reward =  27.000 (best reward= 252.000), step=10739 agent_position = ( -0.412,  0.028,  0.000) 
Episode =  850, reward =  27.000 (best reward= 252.000), step=10748 agent_position = ( -0.411,  0.028,  0.000) 
Episode =  851, reward =  27.000 (best reward= 252.000), step=10757 agent_position = ( -0.395,  0.032,  0.000) 
Episode =  852, reward =  27.000 (best reward= 252.000), step=10766 agent_position = ( -0.561,  0.207,  0.000) 
Episode =  853, reward =  30.000 (best reward= 252.000), step=10776 agent_position = ( -0.648,  0.065,  0.000) 
Episode =  854, reward =  27.000 (best reward= 252.000), step=10785 agent_position = ( -0.535,  0.342,  0.000) 
Episode =  855, reward =  33.000 (best reward= 252.000), step=10796 agent_position = ( -0.476,  0.627,  0.000) 
Episode =  856, reward =  27.000 (best reward= 252.000), step=10805 agent_position = ( -0.584,  0.310,  0.000) 
Episode =  857, reward =  27.000 (best reward= 252.000), step=10814 agent_position = ( -0.411,  0.020,  0.000) 
Episode =  858, reward =  27.000 (best reward= 252.000), step=10823 agent_position = ( -0.373,  0.032,  0.000) 
Episode =  859, reward =  27.000 (best reward= 252.000), step=10832 agent_position = ( -0.447,  0.004,  0.000) 
Episode =  860, reward =  27.000 (best reward= 252.000), step=10841 agent_position = ( -0.517,  0.184,  0.000) 
Episode =  861, reward =  27.000 (best reward= 252.000), step=10850 agent_position = ( -0.547,  0.273,  0.000) 
Episode =  862, reward =  30.000 (best reward= 252.000), step=10860 agent_position = ( -0.309, -0.364,  0.000) 
Episode =  863, reward =  27.000 (best reward= 252.000), step=10869 agent_position = ( -0.420,  0.081,  0.000) 
Episode =  864, reward =  27.000 (best reward= 252.000), step=10878 agent_position = ( -0.580,  0.264,  0.000) 
Episode =  865, reward =  30.000 (best reward= 252.000), step=10888 agent_position = ( -0.476,  0.161,  0.000) 
Episode =  866, reward =  30.000 (best reward= 252.000), step=10898 agent_position = ( -0.359,  0.074,  0.000) 
Episode =  867, reward =  30.000 (best reward= 252.000), step=10908 agent_position = ( -0.285,  0.104,  0.000) 
Episode =  868, reward =  33.000 (best reward= 252.000), step=10919 agent_position = ( -0.403,  0.365,  0.000) 
Episode =  869, reward =  30.000 (best reward= 252.000), step=10929 agent_position = ( -0.145,  0.180,  0.000) 
Episode =  870, reward =  30.000 (best reward= 252.000), step=10939 agent_position = ( -0.226,  0.097,  0.000) 
Episode =  871, reward =  27.000 (best reward= 252.000), step=10948 agent_position = ( -0.235,  0.365,  0.000) 
Episode =  872, reward =  30.000 (best reward= 252.000), step=10958 agent_position = ( -0.144,  0.215,  0.000) 
Episode =  873, reward =  30.000 (best reward= 252.000), step=10968 agent_position = ( -0.167,  0.290,  0.000) 
Episode =  874, reward =  27.000 (best reward= 252.000), step=10977 agent_position = ( -0.406, -0.131,  0.000) 
Episode =  875, reward =  21.000 (best reward= 252.000), step=10984 agent_position = ( -0.054, -0.330,  0.000) 
Episode =  876, reward =  96.000 (best reward= 252.000), step=11016 agent_position = ( -0.156, 16.252,  0.000) 
Episode =  877, reward =  27.000 (best reward= 252.000), step=11025 agent_position = ( -0.296,  0.033,  0.000) 
Episode =  878, reward =  24.000 (best reward= 252.000), step=11033 agent_position = (  0.223,  0.141,  0.000) 
Episode =  879, reward =  27.000 (best reward= 252.000), step=11042 agent_position = (  0.496,  0.071,  0.000) 
Episode =  880, reward = 252.000 (best reward= 252.000), step=11126 agent_position = (  1.439,-17.836, 16.314) 
Episode =  881, reward =  27.000 (best reward= 252.000), step=11135 agent_position = ( -0.834,  0.381,  0.000) 
Episode =  882, reward =  30.000 (best reward= 252.000), step=11145 agent_position = ( -0.620,  0.416,  0.000) 
Episode =  883, reward =  27.000 (best reward= 252.000), step=11154 agent_position = ( -0.307,  0.205,  0.000) 
Episode =  884, reward =  30.000 (best reward= 252.000), step=11164 agent_position = ( -0.151,  0.046,  0.000) 
Episode =  885, reward =  30.000 (best reward= 252.000), step=11174 agent_position = ( -0.172,  0.193,  0.000) 
Episode =  886, reward =  27.000 (best reward= 252.000), step=11183 agent_position = ( -0.245,  0.395,  0.000) 
Episode =  887, reward =  30.000 (best reward= 252.000), step=11193 agent_position = ( -0.297, -0.022,  0.000) 
Episode =  888, reward =  27.000 (best reward= 252.000), step=11202 agent_position = ( -0.421,  0.074,  0.000) 
Episode =  889, reward =  27.000 (best reward= 252.000), step=11211 agent_position = ( -0.019, -0.191,  0.000) 
Episode =  890, reward =  48.000 (best reward= 252.000), step=11227 agent_position = ( -0.008, -0.131,  0.000) 
Episode =  891, reward =  27.000 (best reward= 252.000), step=11236 agent_position = (  0.618,  0.093,  0.000) 
Episode =  892, reward =  30.000 (best reward= 252.000), step=11246 agent_position = ( -0.267,  0.744,  0.000) 
Episode =  893, reward =  27.000 (best reward= 252.000), step=11255 agent_position = ( -0.069,  0.164,  0.000) 
Episode =  894, reward =  27.000 (best reward= 252.000), step=11264 agent_position = ( -0.301,  0.219,  0.000) 
Episode =  895, reward =  33.000 (best reward= 252.000), step=11275 agent_position = ( -0.579,  0.755,  0.000) 
Episode =  896, reward =  36.000 (best reward= 252.000), step=11287 agent_position = ( -0.674,  0.321,  0.000) 
Episode =  897, reward =  30.000 (best reward= 252.000), step=11297 agent_position = ( -0.714,  0.327,  0.000) 
Episode =  898, reward =  30.000 (best reward= 252.000), step=11307 agent_position = ( -0.684,  0.333,  0.000) 
Episode =  899, reward =  30.000 (best reward= 252.000), step=11317 agent_position = ( -0.644,  0.338,  0.000) 
Episode =  900, reward =  30.000 (best reward= 252.000), step=11327 agent_position = ( -0.639,  0.343,  0.000) 
Episode =  901, reward =  30.000 (best reward= 252.000), step=11337 agent_position = ( -0.950,  0.326,  0.000) 
Episode =  902, reward =  24.000 (best reward= 252.000), step=11345 agent_position = (  0.395,  0.178,  0.000) 
Episode =  903, reward =  33.000 (best reward= 252.000), step=11356 agent_position = (  0.559,  2.328,  0.000) 
Episode =  904, reward =  27.000 (best reward= 252.000), step=11365 agent_position = ( -0.727, -0.136,  0.000) 
Episode =  905, reward =  27.000 (best reward= 252.000), step=11374 agent_position = (  0.507,  0.130,  0.000) 
Episode =  906, reward =  21.000 (best reward= 252.000), step=11381 agent_position = (  0.052, -0.373,  0.000) 
Episode =  907, reward =  24.000 (best reward= 252.000), step=11389 agent_position = ( -0.143, -0.270,  0.000) 
Episode =  908, reward =  27.000 (best reward= 252.000), step=11398 agent_position = ( -1.195,  0.113,  0.000) 
Episode =  909, reward =  30.000 (best reward= 252.000), step=11408 agent_position = ( -0.705,  0.605,  0.000) 
Episode =  910, reward =  21.000 (best reward= 252.000), step=11415 agent_position = (  0.112, -0.322,  0.000) 
Episode =  911, reward =  30.000 (best reward= 252.000), step=11425 agent_position = (  0.453,  0.964,  0.000) 
Episode =  912, reward =  21.000 (best reward= 252.000), step=11432 agent_position = (  0.091, -0.351,  0.000) 
Episode =  913, reward =  24.000 (best reward= 252.000), step=11440 agent_position = ( -0.231,  0.043,  0.000) 
Episode =  914, reward =  30.000 (best reward= 252.000), step=11450 agent_position = ( -0.715,  0.338,  0.000) 
Episode =  915, reward =  30.000 (best reward= 252.000), step=11460 agent_position = ( -0.716,  0.332,  0.000) 
Episode =  916, reward =  30.000 (best reward= 252.000), step=11470 agent_position = ( -0.648,  0.335,  0.000) 
Episode =  917, reward =  30.000 (best reward= 252.000), step=11480 agent_position = ( -0.636,  0.341,  0.000) 
Episode =  918, reward =  30.000 (best reward= 252.000), step=11490 agent_position = ( -0.628,  0.359,  0.000) 
Episode =  919, reward =  30.000 (best reward= 252.000), step=11500 agent_position = ( -0.692,  0.328,  0.000) 
Episode =  920, reward =  30.000 (best reward= 252.000), step=11510 agent_position = ( -0.747,  0.319,  0.000) 
Episode =  921, reward =  30.000 (best reward= 252.000), step=11520 agent_position = ( -0.656,  0.336,  0.000) 
Episode =  922, reward =  30.000 (best reward= 252.000), step=11530 agent_position = ( -0.642,  0.343,  0.000) 
Episode =  923, reward =  30.000 (best reward= 252.000), step=11540 agent_position = ( -0.627,  0.347,  0.000) 
Episode =  924, reward =  30.000 (best reward= 252.000), step=11550 agent_position = ( -0.646,  0.356,  0.000) 
Episode =  925, reward =  30.000 (best reward= 252.000), step=11560 agent_position = ( -0.643,  0.351,  0.000) 
Episode =  926, reward =  30.000 (best reward= 252.000), step=11570 agent_position = ( -0.640,  0.322,  0.000) 
Episode =  927, reward =  30.000 (best reward= 252.000), step=11580 agent_position = ( -0.674,  0.323,  0.000) 
Episode =  928, reward =  30.000 (best reward= 252.000), step=11590 agent_position = ( -0.704,  0.327,  0.000) 
Episode =  929, reward =  30.000 (best reward= 252.000), step=11600 agent_position = ( -0.648,  0.341,  0.000) 
Episode =  930, reward =  30.000 (best reward= 252.000), step=11610 agent_position = ( -0.647,  0.332,  0.000) 
Episode =  931, reward =  30.000 (best reward= 252.000), step=11620 agent_position = ( -0.646,  0.335,  0.000) 
Episode =  932, reward =  30.000 (best reward= 252.000), step=11630 agent_position = ( -0.635,  0.331,  0.000) 
Episode =  933, reward =  30.000 (best reward= 252.000), step=11640 agent_position = ( -0.640,  0.335,  0.000) 
Episode =  934, reward =  30.000 (best reward= 252.000), step=11650 agent_position = ( -0.628,  0.346,  0.000) 
Episode =  935, reward =  30.000 (best reward= 252.000), step=11660 agent_position = ( -0.626,  0.331,  0.000) 
Episode =  936, reward =  30.000 (best reward= 252.000), step=11670 agent_position = ( -0.633,  0.338,  0.000) 
Episode =  937, reward =  30.000 (best reward= 252.000), step=11680 agent_position = ( -0.614,  0.338,  0.000) 
Episode =  938, reward =  30.000 (best reward= 252.000), step=11690 agent_position = ( -0.647,  0.343,  0.000) 
Episode =  939, reward =  30.000 (best reward= 252.000), step=11700 agent_position = ( -0.645,  0.330,  0.000) 
Episode =  940, reward =  30.000 (best reward= 252.000), step=11710 agent_position = ( -0.630,  0.322,  0.000) 
Episode =  941, reward =  30.000 (best reward= 252.000), step=11720 agent_position = ( -0.636,  0.330,  0.000) 
Episode =  942, reward =  30.000 (best reward= 252.000), step=11730 agent_position = ( -0.626,  0.346,  0.000) 
Episode =  943, reward =  30.000 (best reward= 252.000), step=11740 agent_position = ( -0.636,  0.338,  0.000) 
Episode =  944, reward =  30.000 (best reward= 252.000), step=11750 agent_position = ( -0.633,  0.334,  0.000) 
Episode =  945, reward =  30.000 (best reward= 252.000), step=11760 agent_position = ( -0.613,  0.336,  0.000) 
Episode =  946, reward =  30.000 (best reward= 252.000), step=11770 agent_position = ( -0.647,  0.335,  0.000) 
Episode =  947, reward =  30.000 (best reward= 252.000), step=11780 agent_position = ( -0.651,  0.327,  0.000) 
Episode =  948, reward =  30.000 (best reward= 252.000), step=11790 agent_position = ( -0.646,  0.349,  0.000) 
Episode =  949, reward =  30.000 (best reward= 252.000), step=11800 agent_position = ( -0.623,  0.341,  0.000) 
Episode =  950, reward =  30.000 (best reward= 252.000), step=11810 agent_position = ( -0.610,  0.337,  0.000) 
Episode =  951, reward =  30.000 (best reward= 252.000), step=11820 agent_position = ( -0.627,  0.344,  0.000) 
Episode =  952, reward =  30.000 (best reward= 252.000), step=11830 agent_position = ( -0.622,  0.339,  0.000) 
Episode =  953, reward =  30.000 (best reward= 252.000), step=11840 agent_position = ( -0.643,  0.329,  0.000) 
Episode =  954, reward =  30.000 (best reward= 252.000), step=11850 agent_position = ( -0.629,  0.318,  0.000) 
Episode =  955, reward =  30.000 (best reward= 252.000), step=11860 agent_position = ( -0.628,  0.346,  0.000) 
Episode =  956, reward =  30.000 (best reward= 252.000), step=11870 agent_position = ( -0.619,  0.330,  0.000) 
Episode =  957, reward =  30.000 (best reward= 252.000), step=11880 agent_position = ( -0.636,  0.338,  0.000) 
Episode =  958, reward =  30.000 (best reward= 252.000), step=11890 agent_position = ( -0.635,  0.334,  0.000) 
Episode =  959, reward =  30.000 (best reward= 252.000), step=11900 agent_position = ( -0.639,  0.340,  0.000) 
Episode =  960, reward =  30.000 (best reward= 252.000), step=11910 agent_position = ( -0.621,  0.347,  0.000) 
Episode =  961, reward =  30.000 (best reward= 252.000), step=11920 agent_position = ( -0.648,  0.345,  0.000) 
Episode =  962, reward =  30.000 (best reward= 252.000), step=11930 agent_position = ( -0.643,  0.337,  0.000) 
Episode =  963, reward =  30.000 (best reward= 252.000), step=11940 agent_position = ( -0.619,  0.347,  0.000) 
Episode =  964, reward =  30.000 (best reward= 252.000), step=11950 agent_position = ( -0.697,  0.344,  0.000) 
Episode =  965, reward =  30.000 (best reward= 252.000), step=11960 agent_position = ( -0.633,  0.342,  0.000) 
Episode =  966, reward =  30.000 (best reward= 252.000), step=11970 agent_position = ( -0.631,  0.324,  0.000) 
Episode =  967, reward =  30.000 (best reward= 252.000), step=11980 agent_position = ( -0.629,  0.339,  0.000) 
Episode =  968, reward =  30.000 (best reward= 252.000), step=11990 agent_position = ( -0.622,  0.343,  0.000) 
Episode =  969, reward =  30.000 (best reward= 252.000), step=12000 agent_position = ( -0.617,  0.335,  0.000) 
Episode =  970, reward =  30.000 (best reward= 252.000), step=12010 agent_position = ( -0.628,  0.335,  0.000) 
Episode =  971, reward =  30.000 (best reward= 252.000), step=12020 agent_position = ( -0.626,  0.363,  0.000) 
Episode =  972, reward =  30.000 (best reward= 252.000), step=12030 agent_position = ( -0.634,  0.329,  0.000) 
Episode =  973, reward =  30.000 (best reward= 252.000), step=12040 agent_position = ( -0.622,  0.344,  0.000) 
Episode =  974, reward =  30.000 (best reward= 252.000), step=12050 agent_position = ( -0.611,  0.332,  0.000) 
Episode =  975, reward =  30.000 (best reward= 252.000), step=12060 agent_position = ( -0.595,  0.349,  0.000) 
Episode =  976, reward =  30.000 (best reward= 252.000), step=12070 agent_position = ( -0.653,  0.327,  0.000) 
Episode =  977, reward =  30.000 (best reward= 252.000), step=12080 agent_position = ( -0.632,  0.335,  0.000) 
Episode =  978, reward =  30.000 (best reward= 252.000), step=12090 agent_position = ( -0.643,  0.344,  0.000) 
Episode =  979, reward =  30.000 (best reward= 252.000), step=12100 agent_position = ( -0.627,  0.338,  0.000) 
Episode =  980, reward =  30.000 (best reward= 252.000), step=12110 agent_position = ( -0.636,  0.342,  0.000) 
Episode =  981, reward =  30.000 (best reward= 252.000), step=12120 agent_position = ( -0.646,  0.329,  0.000) 
Episode =  982, reward =  30.000 (best reward= 252.000), step=12130 agent_position = ( -0.623,  0.329,  0.000) 
Episode =  983, reward =  30.000 (best reward= 252.000), step=12140 agent_position = ( -0.636,  0.329,  0.000) 
Episode =  984, reward =  30.000 (best reward= 252.000), step=12150 agent_position = ( -0.633,  0.339,  0.000) 
Episode =  985, reward =  30.000 (best reward= 252.000), step=12160 agent_position = ( -0.632,  0.339,  0.000) 
Episode =  986, reward =  30.000 (best reward= 252.000), step=12170 agent_position = ( -0.622,  0.331,  0.000) 
Episode =  987, reward =  30.000 (best reward= 252.000), step=12180 agent_position = ( -0.640,  0.341,  0.000) 
Episode =  988, reward =  30.000 (best reward= 252.000), step=12190 agent_position = ( -0.637,  0.343,  0.000) 
Episode =  989, reward =  30.000 (best reward= 252.000), step=12200 agent_position = ( -0.631,  0.335,  0.000) 
Episode =  990, reward =  30.000 (best reward= 252.000), step=12210 agent_position = ( -0.623,  0.355,  0.000) 
Episode =  991, reward =  30.000 (best reward= 252.000), step=12220 agent_position = ( -0.646,  0.334,  0.000) 
Episode =  992, reward =  30.000 (best reward= 252.000), step=12230 agent_position = ( -0.630,  0.329,  0.000) 
Episode =  993, reward =  30.000 (best reward= 252.000), step=12240 agent_position = ( -0.620,  0.351,  0.000) 
Episode =  994, reward =  30.000 (best reward= 252.000), step=12250 agent_position = ( -0.629,  0.339,  0.000) 
Episode =  995, reward =  30.000 (best reward= 252.000), step=12260 agent_position = ( -0.628,  0.337,  0.000) 
Episode =  996, reward =  30.000 (best reward= 252.000), step=12270 agent_position = ( -0.640,  0.328,  0.000) 
Episode =  997, reward =  30.000 (best reward= 252.000), step=12280 agent_position = ( -0.621,  0.349,  0.000) 
Episode =  998, reward =  30.000 (best reward= 252.000), step=12290 agent_position = ( -0.625,  0.349,  0.000) 
Episode =  999, reward =  30.000 (best reward= 252.000), step=12300 agent_position = ( -0.627,  0.343,  0.000) 
Episode = 1000, reward =  30.000 (best reward= 252.000), step=12310 agent_position = ( -0.667,  0.353,  0.000) 
